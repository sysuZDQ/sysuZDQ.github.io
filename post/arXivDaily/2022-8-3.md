 Unified Normalization for Accelerating and Stabilizing Transformers    
 Transformers的可靠结果使其成为各种自然语言和视觉任务中的主流架构。（LN）规范化每个令牌内的激活以提高鲁棒性，但LN在推理过程中需要实时统计计算以及除法和开方运算，导致硬件效率低下，用其他硬件高效的归一化方案替换LN本文提出了一种基于激活统计量的训练算法，该算法在训练过程中，由于激活统计量的异常行为（迭代过程中的大幅度波动和层间的极端异常值）而导致训练性能下降，甚至崩溃，为了解决这些问题，我们提出统一规范化（UN），该算法通过与其他线性运算的融合来提高推理速度，并通过调整波动平滑策略来校正激活统计量和梯度统计量，以达到与LN相当的性能，同时，本文提出了一种自适应离群点过滤策略来避免训练过程中的崩溃，并从理论上和实验上证明了该策略的有效性，证明了联合神经网络是一种有效的降维算法.通过在语言和视觉任务上的大量实验，我们提出了一种新的基于UN的算法，以替代LN.此外，我们还在GPU上评估了我们的算法的效率.配备UN的Transformer获得了大约31%的推理加速和将近18%的内存减少.代码将在https： github.com hikvision-research Unified-Normalization.   
 transformer的优化    

 -----    
 Prompt-to-Prompt Image Editing with Cross Attention Control      
 近年来，基于文本的大规模图像合成模型由于能够根据文本提示生成高度多样的图像而受到广泛关注.这种基于文本的图像合成方法对于习惯于口头描述其意图的人来说特别有吸引力.因此，将文本驱动的图像合成扩展到文本驱动的图像编辑是很自然的.编辑对于这些生成模型来说是具有挑战性的.由于编辑技术的固有特性是保留原始图像的大部分，而在基于文本的模型中，即使对文本提示进行很小的修改也会导致完全不同的结果.现有的方法通过要求用户提供一个空间掩模来定位编辑，从而忽略了掩模区域内的原始结构和内容.本文提出了一种新的基于文本的编辑方法，我们追求一个直观的提示—提示编辑框架，在这个框架中编辑只由文本控制.为此，我们深入分析了文本条件化模型，并观察到交叉注意层是控制图像的空间布局与提示中每个单词之间关系的关键.基于这个观察，我们介绍了几个只通过编辑文本提示来监控图像合成的应用程序，包括通过替换一个单词进行本地化编辑，通过添加一个规范进行全局编辑，和提示上呈现我们的结果，展示了高质量的合成以及对编辑后的提示的保真度。     
 交叉注意力   
 
 ------    
 BERT4Loc: BERT for Location -- POI Recommender System    
 兴趣点推荐是一个需要从基于位置的社交媒体平台中提取精确位置信息的难题.基于用户历史行为的偏好建模是此类位置感知推荐系统的另一个挑战性和关键问题.本文提出了一个基于双向编码表示的位置感知推荐系统，旨在为用户提供位置信息.该系统采用了一种基于双向编码表示的位置感知推荐方法，并在此基础上设计了一个基于双向编码表示的位置感知推荐系统.该系统具有良好的用户体验，并能为用户提供更好的位置信息该模型将位置数据和用户偏好相结合，与预测序列中每个位置的下一个感兴趣的项目（位置）相比，该模型可以为用户提供更相关的结果.在基准数据集上的大量实验表明，该模型的性能始终优于各种现有的序列模型    
 BERT的应用  

 ------    
 A Comparative Study on COVID-19 Fake News Detection Using Different Transformer Based Models    
 社交网络的快速发展和互联网可用性的便利加速了虚假新闻和谣言在社交媒体网站上的猖獗传播。在新冠肺炎疫情中，这种误导性信息使人们的精神和身体生命处于危险之中，从而加剧了这种情况。为了限制这种不准确的传播，在本研究中，作者通过实现BERT、BERT without LSTM、ALBERT、RoBERTa以及一个混合的BERT & ALBERT来检测来自互联网的COVID 19虚假新闻。我们使用COVID 19虚假新闻数据集来训练和测试这些模型。在所有这些模型中，RoBERTa模型表现得比其他模型更好，在真实和虚假类别中都获得了0.98的F1得分。   
 这种跟热点的不知道能发什么级别    

 -------   
 To Answer or Not to Answer? Improving Machine Reading Comprehension Model with Span-based Contrastive Learning   
 带不可回答问题的机器阅读理解是一项困难的自然语言处理任务，它面临着从文章中无法回答的问题的挑战。人们注意到，细微的文字变化常常使一个可回答的问题变成不可回答的，然而大多数MRC模型未能识别这种变化。为了解决这一问题，本文提出了一种新的机器阅读理解模型——-MRC模型，我们提出了一种基于广度的对比学习方法（spanCL）在答案跨度级别上明确地将可回答的问题与它们的可回答和不可回答的对应问题进行对比。在SQuAD2.0数据集上的实验表明，spanCL能显著提高基线，得到0.86-2.14的绝对EM改进，是一种有效利用生成问题的方法   
 对MRC任务的改进  

 -----   
 