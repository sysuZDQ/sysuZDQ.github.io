 Multi-Granularity Distillation Scheme Towards Lightweight Semi-Supervised Semantic Segmentation     
 尽管半监督语义切分技术取得了不同程度的进展，但其最新的成功大多涉及笨重的模型，而轻量级的解决方案尚未被探索。我们发现现有的知识提取技术更多地关注来自标记数据的像素级概念，而没有考虑未标记数据中的更多信息线索。因此，我们首次尝试通过一种新颖的多粒度蒸馏（MGD）方案来提供轻量级SSSS模型，其中多粒度从三个方面捕获：（一）教师结构互补; ii）标记—未标记数据协同提取; ③分层次、多层次定损。具体地说，MGD被描述为一个标记—未标记数据协作提取方案，它有助于充分利用半监督环境中所必需的不同数据特征.通过建立图像级语义敏感损失、区域级内容感知损失和像素级一致性损失，利用结构互补的教师丰富层次提炼抽象。在PASCAL VOC2012和Cityscapes上的实验结果表明，在不同的划分协议下，MGD算法的性能均优于同类算法.以Cityscapes为例，在1 16分区协议下，ResNet-18和MobileNet-v2骨干网的性能分别提升了11.5%和4.6%。虽然模型主干的FLOP被3.4-5.3x（ResNet-18）和38.7-59.6x（MobileNetv2）压缩，但是该模型设法实现令人满意的分割结果     
 一种提取多种粒度信息的方法

 -----
 Prompt-Matched Semantic Segmentation    
 本工作的目标是探索如何有效地和高效地使预先训练好的基础模型适应图像语义分割的各种下游任务。传统的方法通常针对每个特定的数据集对整个网络进行微调，并且存储这些网络的海量参数是一项繁重的工作。一些最近的工作试图将一些可训练的参数插入冻结的网络中，以学习用于有效调谐的视觉提示。然而，这些工作显著地修改了标准模块的原始结构，使得它们不能在许多现有的高速推理设备上操作，其中标准模块和它们的参数已经被嵌入。为了便于基于提示的语义切分，提出了一种新的阶段间提示匹配框架，该框架在保持基础模型原有结构的同时，自适应地生成视觉提示，以实现面向任务的调优.具体地，预先训练的模型首先被划分为多个阶段，并且它们的参数被冻结并且对于所有语义分割任务共享。然后引入一个轻量级的语义感知提示匹配器模块，在中间语义映射的指导下，在两个阶段之间进行分层插值，为每个特定任务学习合理的提示。通过这种方式，我们可以更好地激励冻结模型的预先训练的知识，以在下游数据集上有效地学习语义概念。在5个基准测试上的实验结果表明，该方法能够在参数效率和性能效率之间取得较好的平衡     
 如何使用prompt使得预训练模型高效地适应语义分割任务

 ----
 Revising Image-Text Retrieval via Multi-Modal Entailment    
 一个优秀的图文检索模型依赖于高质量的标注数据。虽然现有图像—文本检索数据集的构建者努力确保标题与链接的图像匹配，但他们无法阻止标题适合其他图像。我们观察到这种多对多匹配现象在广泛使用的检索数据集中相当普遍，其中一个标题可以描述多达178幅图像。这些大量的匹配丢失数据不仅使模型在训练过程中产生混乱，而且降低了评价的准确性。受视觉和文本蕴涵任务的启发，我们提出了一种多模态蕴涵分类器来判断句子是否由图像及其链接的标题所蕴涵。随后，我们通过添加这些隐含字幕作为图像的附加弱标签来修改图像—文本检索数据集，并开发了一种通用的可变学习率策略来教导检索模型区分隐含字幕和其他负面样本。在实验中，我们手动标注了一个隐含校正的图像—文本检索数据集以进行评估。实验结果表明，所提蕴涵分类器的分类准确率达到了78%，提高了图文检索基线的性能。     
 提出模型以修正数据集的不足

 -----
 SDBERT: SparseDistilBERT, a faster and smaller BERT model    
 本文提出了一种新的Transformer结构—-SparseDistilBERT（SDBERT），它是稀疏注意和知识提取（KD）的结合。我们实现了稀疏注意机制，以减少对输入长度的二次依赖为线性。除了降低模型的计算复杂度外，我们还使用了知识蒸馏（KD）。我们能够将BERT模型的大小减少60%，同时保持97%的性能，并且只需要40%的时间来训练      
 更小更快的BERT

 -----
 Semantic-enhanced Image Clustering    
 图像聚类是计算机视觉中一个重要的、具有挑战性的课题。虽然已经提出了许多方法来解决图像聚类问题，**但是这些方法仅仅是根据图像的特征对图像进行探索和聚类，无法区分视觉上相似但语义上不同的图像**。本文提出了一种基于视觉语言预训练模型的图像聚类算法。与已知类名的zero-shot设置不同，在此设置中我们只知道聚类的数量。因此，如何将图像映射到一个合适的语义空间，以及如何从图像空间和语义空间对图像进行聚类是两个关键问题。为了解决上述问题，本文提出了一种基于视觉语言预训练模型CLIP的图像聚类方法，命名为 textbf{Semantic-enhanced Image Clustering（SIC）}.该方法首先将图像映射到合适的语义空间，然后根据图像与语义的关系生成伪标签。最后，我们提出在图像空间和语义空间中以自监督学习的方式执行一致性学习的聚类。收敛性分析的理论结果表明，该方法能以亚线性速度收敛.对期望风险的理论分析也表明，可以通过提高邻域一致性或预测置信度或减少邻域不平衡性来降低期望风险。在5个基准数据集上的实验结果表明了新方法的优越性      
 发现的问题很敏锐！


 ----
 
