Learning More May Not Be Better: Knowledge Transferability in Vision and Language Tasks    
更多的数据总是更好地训练视觉和语言模型吗？研究了多模态任务中的知识转移问题。目前机器学习的趋势是假设通过连接来自不同任务的多个数据集，它们的整体性能将得到改善。然而，我们表明，并不是所有的知识都能很好地传递或对相关任务产生积极影响，即使它们有共同的目标。本研究对12个视觉语言任务进行了大量的交叉实验，并将其分为4组。虽然同一组中的任务倾向于相互改进，但结果表明情况并非总是如此。其他因素，如数据集大小或预训练阶段，也对知识的转移有很大的影响     
论证是不是数据越多越好 

-----
The Value of Out-of-Distribution Data     
更多的数据有助于我们概括一项任务。但是真实的数据集可能包含分布外（OOD）数据;这可以以异质性的形式出现，例如类内差异，也可以以时间转移或概念漂移的形式出现。我们为这样的问题论证了一个反直觉的现象：任务的泛化误差可以是OOD样本数量的非单调函数;少量的OOD样本可以改进泛化，但是如果OOD样本的数量超过阈值，则泛化误差会恶化。我们还表明，如果我们知道哪些样本是面向对象的，那么在目标样本和面向对象样本之间使用加权目标确保泛化误差单调下降。我们使用合成数据集上的线性分类器和CIFAR-10上的中型神经网络来演示和分析这个问题。     
对OOD的研究

------
Learning Better Masking for Better Language Model Pre-training    
掩蔽语言模型（MLM）作为预训练语言模型（PrLMs）中的去噪目标得到了广泛应用。现有的PrLMs通常采用随机标记掩蔽策略，其中应用固定的掩蔽比率，并且在整个训练过程中以相等的概率掩蔽不同的内容。然而，随着训练时间的延长，模型会受到训练前状态的复杂影响，本文证明了这种对掩蔽率和掩蔽内容的时不变MLM设置不可能产生最优结果，这激发了我们探索时变MLM设置的影响。提出了两种调度掩蔽方法，在不同的训练阶段自适应地调整掩蔽率和掩蔽内容，提高了预训练的效率，并在下游任务上验证了该方法的有效性.本文的工作是对掩蔽比率和掩蔽内容的时变掩蔽策略的开创性研究，使我们更好地理解掩蔽比率和掩蔽内容如何影响MLM预训练。       
对掩码机制的深入研究

-----