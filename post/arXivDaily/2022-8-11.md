Language Supervised Training for Skeleton-based Action Recognition  
基于骨架的动作识别由于其计算效率高和对光照条件的鲁棒性而受到广泛关注.现有的基于骨架的动作识别方法通常被表述为一个单热点分类任务，没有充分利用动作之间的语义关系.例如，“做胜利手势”和“竖起大拇指”是手势中的两个动作，这些信息与动作类别的分类编码是不可知的，但可以在动作的语言描述中揭示出来，因此，在训练中利用动作语言描述可能有益于表征学习.在这项工作中，我们建议进行语言督导培训（LST）方法，更具体地说，我们使用一个大规模的语言模型作为知识引擎来提供动作的身体部分运动的文本描述，提出了一种多模态训练方案，利用文本编码器为不同的身体部位生成特征向量，并监督骨架编码器进行动作表示学习。实验结果表明，LST方法在不增加推理计算量的情况下，取得了明显的改进，在NTU RGB+D、NTU RGB+D 120和NW-UCLA等基于骨架的动作识别基准测试中取得了新的进展，代码可在https： github.com MartinXM LST.    
使用语言辅助动作识别任务的表示，这种思想可以迁移到用语言辅助图像理解上  

-----
Multi-task Active Learning for Pre-trained Transformer-based Models   
在多任务学习中，多个任务由单个模型共同学习，这允许NLP模型共享来自多个注释的信息，并且当任务相互关联时可以促进更好的预测。需要使用多种注释方案对同一文本进行注释，这可能是昂贵且费力的。（AL）通过迭代选择对NLP模型最有价值的未标注样本来优化标注过程，多任务主动学习（MT-AL）还没有被应用到目前最先进的基于Transformer的NLP模型中，本文旨在弥补这一空白，我们在三个现实的多任务场景中探讨了各种多任务选择准则，实验结果表明，MT-AL可以有效地减少多任务NLP模型的标注工作量，从而提高多任务NLP模型的效率.   
一个NLP模型做多个任务  

----
How Effective is Byte Pair Encoding for Out-Of-Vocabulary Words in Neural Machine Translation?   
神经机器翻译（NMT）是一个开放性的词汇问题，因此，处理训练中没有出现的单词长期以来，词汇表外（OOV）单词一直是NMT系统面临的一个基本挑战，解决这个问题的主要方法是字节对编码（BPE），其将单词，包括OOV单词，BPE在自动评估标准方面为各种翻译任务取得了令人印象深刻的结果。本文从词的类型、分词数量、交叉注意权值以及词与词之间的关系等方面分析了BPE在处理OOV词时的翻译质量，并对BPE在处理OOV词时的翻译效果进行了评价，实验结果表明，尽管仔细的BPE设置在跨数据集的OOV词翻译中似乎是相当有用的，但是相当大比例的OOV词被错误地翻译了.此外，我们还强调了BPE在特殊情况下的OOV词翻译中略高的有效性，例如命名实体，以及所涉及的语言在语言学上彼此接近时。   
机器翻译中的OOV问题   

-------
Attention Hijacking in Trojan Transformers    
木马攻击对人工智能系统构成了严重的威胁。最近关于Transformer模型的研究受到了爆炸性的欢迎，并且自我关注现在是无可争议的。这就提出了一个核心问题：我们能否通过BERT和ViT中的注意力机制来发现木马呢？本文研究了木马AI中的注意力劫持模式，当一个特定的触发器出现时，触发器令牌''绑架''了注意力权重。我们从自然语言处理和（NLP）和计算机视觉（CV）域的特征，这一有趣的特性有助于我们理解BERT和ViT中的木马机制，我们还提出了一个注意力劫持木马检测器（AHTD）来区分木马AI和干净的AI。   
一个比较有意思的应用   

-------
 Fast Offline Policy Optimization for Large Scale Recommendation   
 个性化交互系统如推荐系统需要根据上下文选择相关的项目.生产系统需要从非常大的目录中快速识别项目，这可以使用最大内积搜索技术来有效地解决.最大内积搜索的离线优化可以通过松弛离散问题来实现，从而导致策略学习或加强风格学习算法.不幸的是，该松弛步骤需要计算整个目录上的总和，使得梯度的评估复杂这种计算在诸如大目录推荐系统的许多真实世界示例中是不成立的，严重限制了这种方法在实践中的有用性。在这篇文章中，我们展示了如何能够产生这些策略学习算法的一个极好的近似，这些算法与目录大小成对数比例。一种新的策略梯度的MonteCarlo估计，自归一化重要抽样估计，以及在训练时使用快速最大内积搜索.大量的实验表明，我们的算法比原始方法快一个数量级，但产生同样好的策略.   
 大规模推荐系统的优化  

 -----
 PEPPER: Empowering User-Centric Recommender Systems over Gossip Learning   
 推荐系统被证明是一个非常有价值的工具，用于提取用户相关的内容，帮助用户在他们的日常活动（例如，查找要访问的相关地点、要消费的内容、要购买的物品）。然而，为了有效，这些系统需要收集和分析大量的个人数据（例如，位置签到、电影评级、点击率等），这使用户暴露于许多隐私威胁。基于联邦学习的推荐系统（FL）似乎是一种有前途的用于实施隐私的解决方案，因为它们计算准确的推荐，同时在用户的设备上保留个人数据。和基于FL的推荐系统，依赖于一个中央服务器，除了易受攻击外，还可能遇到可扩展性问题.为了解决这个问题，我们提出了一个基于闲谈学习原理的去中心化推荐系统PEPPER.在PEPPER中，用户闲谈模型异步地更新并聚合它们. PEPPER的核心有两个关键组件：一个个性化的对等采样协议，在每个节点的邻域中保留一部分与前者有相似兴趣的节点，以及一个简单而有效的模型聚集函数，建立一个更适合每个用户的模型。位置登记推荐和电影推荐，我们证明了我们的解决方案比其他分散式解决方案的收敛速度快42%，与分散式竞争对手相比，平均性能指标（如命中率）提高了9%，长尾性能提高了21%。   
 推荐系统  

 -----
 