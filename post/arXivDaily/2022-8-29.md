Cross-Lingual Cross-Modal Retrieval with Noise-Robust Learning    
尽管近年来跨模态检索领域取得了长足的发展，但由于缺乏人工标注的数据集，针对低资源语言的研究较少。针对低资源语言，提出一种抗噪的跨语言跨模态检索方法.为此，我们使用机器翻译（MT）为低资源语言构造伪平行句子对。然而，由于机器翻译的不完善性，它在翻译过程中容易引入噪声，使得文本嵌入被破坏，从而影响检索性能。为了解决这一问题，本文提出了一种多视角自提取方法来学习噪声鲁棒的目标语言表示，该方法利用交叉注意模块生成软伪目标，从基于相似度的视角和基于特征的视角提供直接监督。此外，受无监督机器翻译中回译的启发，我们最小化原始句子和回译句子之间的语义差异，以进一步提高文本编码器的噪声鲁棒性。在三个跨语言的视频—文本和图像—文本跨模态检索基准上进行了大量实验，实验结果表明，该方法在不使用额外人工标注数据的情况下显著提高了整体性能.此外，配备有来自最近的视觉和语言预训练框架的预训练的视觉编码器，即，CLIP的测试结果表明，该方法与常用的预训练模型具有良好的兼容性.有关代码和数据，请访问https: github.com HuiGuanLab nrccr     
使用了机器翻译为为低资源语言构造伪平行句子对，并解决了其中的噪声问题

----
AiM: Taking Answers in Mind to Correct Chinese Cloze Tests in Educational Applications     
为了自动更正手写作业，传统的方法是使用OCR模型来识别字符并将其与答案进行比较。OCR模型在识别手写体汉字时容易产生混淆，模型推理过程中容易丢失答案的文本信息。然而，老师们总是把这些答案记在心里，以便复习和批改作业。本文针对汉语完形填空测试的纠错问题，提出了一种多模态方法（AiM）。答案的编码表示与学生手写的视觉信息交互。我们对答案文本进行序列标注，以细粒度的方式推断哪个答案字符与手写内容不同，而不是预测“对”或“错”。我们以OCR数据集的样本作为本任务的正样本，并开发了一种负样本扩充方法来扩大训练数据。实验结果表明，AiM的性能明显优于基于OCR的方法。大量的研究证明了我们的多模态方法的有效性。   
自动更正手写作业的模型

----
