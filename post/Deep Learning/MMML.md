# Multimodal Machine Learning

本文的前面的介绍内容基于2019年的一篇综述论文[Multimodal Machine Learning:A Survey and Taxomony](https://people.ict.usc.edu/~gratch/CSCI534/Readings/Baltrusaitis-MMML-survey.pdf#:~:text=Multimodal%20machine%20learning%20aims%20to%20build%20models%20that,%EF%AC%81eld%20of%20increasing%20importance%20and%20with%20extraordinary%20potential.)    

对于多模态机器学习没有基础概念的同学，可以事先阅读该篇[博客](https://zhuanlan.zhihu.com/p/53511144)。   

-----
我们所处的世界是多模态的，我们可以看见、听见，摸到、闻到、尝到......   
显然，如果我们的模型也能像人类一样，从多个角度去观察事物，那么它得到的信息肯定更加地全面、准确。   
目前来说，MMML面临的挑战包括 representation, translation, alignment, fusion, and co-learning   
当下，我们主要关注三种模态：既可以写也可以说的自然语言；通常用图像或视频表示的视觉信号；编码声音和副词信息的声音信号，如韵律、声乐等。
具体来说，这五个挑战是
- **表示**：第一个基本挑战是学习如何以一种利用多种模态的互补性和冗余性的方式表示和汇总多模式数据。多模数据的异构性使得构造这样的表示方法具有挑战性。例如，语言通常是象征性的，而音频和视频形式将被表示为信号。
- **翻译**：第二个挑战是如何将数据从一种模式转换(映射)到另一种模式。不仅异构数据，而且模式之间的关系往往是开放的或主观的。例如，有许多正确的方法来描述一个图像，一个完美的映射可能不存在。
- **对齐**：第三个挑战是确定来自两种或两种以上不同模式的(子)元素之间的直接关系。例如，我们可能希望将菜谱中的步骤与显示正在制作的菜肴的视频对齐。为了解决这一挑战，我们需要度量不同模式之间的相似性，并处理可能的长期依赖性和模糊性。
- **融合**：第四个挑战是连接来自两个或多个模式的信息来执行预测。例如，在视听语音识别中，将唇动的视觉描述与语音信号融合，预测语音单词。来自不同模式的信息可能具有不同的预测能力和噪声拓扑结构，其中至少有一种模式可能丢失数据。
- **共同学习**：第五个挑战是在模态、它们的表示和它们的预测模型之间传递知识。这一点可以用协同训练、概念基础和零样本学习的算法来举例说明。协同学习探索了从一个模态中学习知识如何帮助在不同模态中训练的计算模型。当其中一种模式的资源有限（例如，注释数据）时，这一挑战尤其重要。   

## 多模态表示
以计算模型可以使用的格式表示原始数据一直是机器学习中的一大挑战。表示多种形式存在许多困难：如何组合来自不同来源的数据；如何处理不同级别的噪声；以及如何处理丢失的数据。以有意义的方式表示数据的能力对于多模式问题至关重要，并且是任何模型的主干。    
Bengio发现一个好的表示应该具有属性：smoothness, temporal and spatial coherence, sparsity, and natural clustering amongst others.后人还发现了其他的理想属性：similarity in the representation space
should reflect the similarity of the corresponding concepts,
the representation should be easy to obtain even in the
absence of some modalities, and finally, it should be possible
to fill-in missing modalities given the observed ones.    
目前大部分的视觉描述都是通过神经网络(CNN)等神经结构从数据中学习的，自然语言使用利用单词上下文的数据驱动的单词嵌入来表示。以前的多模态表示就是简单地将这些但模态表示拼接起来。   
为了帮助理解工作的广度，我们提出了两类多模态表示:联合和协调。联合表示将单模态信号组合到同一个表示空间中，而协调表示单独处理单模态信号，但对其施加一定的相似性约束（如线性相关），使其达到我们所说的协调空间
<div align=center><img src="..\..\image\MMML\5b1a794b8437af7ee3857a9ff1aa9e7.jpg" width="500"></div> 
  
  - 联合表示   
  联合表示法主要（但不是唯一）用于在训练和推理步骤中同时存在多模态数据的任务。联合表示的最简单示例是单个模态特征的串联。在本节中，我们讨论了创建联合表示的更先进的方法，首先是神经网络，然后是图形模型和循环神经网络。   
  神经网络已成为一种非常流行的单模态数据表示方法。它们用于表示视觉、声学和文本数据，并且越来越多地用于多模态领域。由于深层神经网络的多层性，假设每一层后续的神经网络以更抽象的方式来表示数据，因此通常使用最后一层或倒数第二层神经网络作为一种数据表示形式。为了使用神经网络构建一个多模态表示，每个模态都从几个单独的神经层开始，然后是一个隐藏层，该层将模态投射到一个共同空间。由于神经网络需要大量带标签的训练数据，因此通常使用自动编码器对无监督数据进行预训练。   
  概率图形模型是另一种通过使用潜在随机变量来构造表示的常用方法。基于图形模型的表示最流行的方法是受限玻尔兹曼机：deep Boltzmann machines (DBM)，将restricted Boltzmann machines (RBM)堆叠起来作为构建块。与神经网络类似，DBM的每个连续层都期望在更高的抽象级别上表示数据。DBMs的吸引力来自于他们不需要监督数据进行训练的事实。  
  到目前为止，RNNs主要用于表示单模态的单词、音频或图像序列，在语言领域取得了很大的成功。   
  - 协同表示   
  联合多模表示的一种替代方法是协同表示。我们不是将模态一起投影到一个联合空间中，而是为每个模态学习单独的表示，但是通过一个约束来协调它们。我们从强调表示之间的相似性的协调表示开始讨论，接着讨论在结果空间上加强结构的协调表示    
  在本节中，我们确定了两种主要的多模态表示形式——联合和协调。联合表示将多模态数据投射到一个公共空间中，最适合在推理过程中出现所有模态的情况。它们被广泛用于AVSR、情感和多模手势识别。另一方面，协调表示法将每个模态投影到一个单独但协调的空间中，使其适用于测试时只有一个模态的应用，例如：多模态检索和翻译（第4节）、接地（第7.2节）和零镜头学习（第7.2节）。最后，虽然联合表示用于构建两种以上模态的表示，但到目前为止，协调空间主要限于两种模态。   
  <div align=center><img src="..\..\image\MMML\e2ef507aad54ca7c344e7efc8e6b4cc.jpg" width="500"></div> 

## 多模态转化
多模机器学习的很大一部分涉及从一种形式到另一种形式的翻译（映射）。给定一个模态中的实体，任务是用不同的模态生成相同的实体。例如，给定一个图像，我们可能希望生成一个描述它的句子，或者给定一个文本描述，生成一个匹配它的图像。多模态翻译是一个长期研究的问题，在语音合成、视觉语音生成、视频描述、跨模态检索等领域都有早期的工作。   
虽然多模态翻译的方法非常广泛，而且通常是模态特有的，但它们有许多共同的因素。我们将它们分为两类——基于实例的和生成的。基于实例的模型在模式之间转换时使用字典。   
<div align=center><img src="..\..\image\MMML\76d6b148505247910e3c09d22426a6a.jpg" width="500"></div> 

- 基于实例     
  基于实例的算法受到训练数据字典的限制(见图2a)。我们确定了这类算法的两种类型:基于检索的算法和基于组合的算法。基于检索的模型直接使用检索到的转换，而不需要修改它，而基于组合的模型依赖于更复杂的规则来基于大量检索到的实例创建转换。   
  基于检索的模型可以说是多模态翻译的最简单形式。它们依赖于在字典中找到最接近的样本，并将其用作翻译结果。检索可以在单模态空间或中间语义空间进行。   
  语义空间中的检索方法往往比单模态的检索方法表现得更好，因为它们是在一个更有意义的空间中检索示例，该空间反映了两种模式，而且通常是为检索而优化的。此外，它们允许双向翻译，这在单模态方法中不是很直观。然而，它们需要手工构建或学习这样的语义空间，这通常依赖于大型训练字典(成对样本的数据集)的存在。   
  基于组合的模型进一步采用了基于检索的方法。它们不只是从字典中检索示例，而是以一种有意义的方式将它们组合起来，以构建更好的翻译。基于组合的媒体描述方法的出发点是图像的句子描述具有共性和简单性可以利用的结构。组合规则通常是手工制定的或基于启发式的。    
  
- 生成方法    
  在给定单模源实例的情况下，多模翻译的生成方法构造了能够执行多模翻译的模型。这是一个具有挑战性的问题，因为它需要同时理解源模态和生成目标序列或信号的能力。正如下面一节所讨论的，由于可能的正确答案空间很大，这也使得这些方法更难评估。    

多模态翻译方法面临的一个主要挑战是很难对其进行评价。虽然语音识别等任务只有一个正确的翻译，但语音合成和媒体描述等任务没有。有时，就像在语言翻译中一样，多个答案都是正确的，决定哪个翻译更好往往是主观的。幸运的是，在模型评估中有许多近似的自动度量。   
通常，评价主观任务的理想方法是通过人的判断。那就是让一组人评估每一个翻译。   
虽然人类研究是评估的黄金标准，但已经为媒体描述的任务提出了许多自动替代方案：BLUE、ROUGE、Meteor和CIDEr。这些指标直接取自(或基于)机器翻译中的工作，并计算出度量两者之间相似性的得分生成的和基本的真实文本。    
基于检索的系统不是生成标题，而是根据标题与图像的匹配程度对可用标题进行排序，然后通过评估正确的标题是否具有较高的排名来进行评估。    
我们认为，解决评价问题对多式翻译系统的进一步成功至关重要。这样不仅可以更好地比较各种方法，而且可以优化更好的目标。    

## 多模态对齐   
我们将多模态对齐定义为从两个或多个模态中查找实例子组件之间的关系和对应。例如，给定一幅图像和一个标题，我们希望找到与标题的单词或短语对应的图像区域。另一个例子是，给定一部电影，将其与剧本或书中它所基于的章节进行比对。     
我们将多模态对齐分为隐式对齐和显式对齐两种类型。在显式对齐中，我们显式地对在模式之间对齐子组件感兴趣，例如，使用相应的教学视频对齐菜谱步骤。隐式对齐用作另一个任务的中间(通常是隐藏)步骤，例如，基于文本描述的图像检索可以包括单词和图像区域之间的对齐步骤。   

- 显式对齐    
  如果论文的主要建模目标是来自两个或多个模式的实例子组件之间的对齐，那么我们将其归类为执行显式对齐。显式对齐的一个非常重要的部分是相似性度量。大多数方法依赖于以不同模式度量子组件之间的相似性作为基本构建块。这些相似性可以手动定义，也可以从数据中学习。    
  我们确定了两种处理显式对齐的算法——无监督算法和(弱)监督算法。第一种类型不使用直接对齐标签(即来自不同模式的实例之间的通信。第二种类型可以访问这些(有时是弱)标签。   
  无监督的多模式校准解决了模式校准而无需任何直接校准标签。大多数方法都是从早期的统计机器翻译校准工作和基因组序列中得到启发的。为了使任务更简单，这些方法假定了对对齐的某些约束，例如序列的时间顺序或模式之间存在相似性度量。   
  监督对齐方法依赖于标记对齐的实例。它们用于训练用于对齐模式的相似性度量。    
- 隐式对齐     
  与显式对齐相反，隐式对齐用作另一个任务的中间(通常是隐藏)步骤。这使得在许多任务中，包括语音识别、机器翻译、媒体描述和视觉问答，可以获得更好的性能。这类模型不显式地对齐数据，也不依赖于监督对齐示例，而是学习如何在模型培训期间对数据进行隐式对齐。我们确定了两种类型的隐式对齐模型:早期基于图形模型的工作和更现代的神经网络方法。   
  图形模型已经看到了一些早期的工作，用于更好地对齐机器翻译语言之间的单词和语音音素与其转录的对齐。但是，它们需要手动构造模式之间的映射，例如，将电话映射到声学特性的生成电话模型。构建这样的模型需要培训数据或人类专业知识来手动定义它们。   
  神经网络转换是一个建模任务的例子，如果将对齐作为潜在的中间步骤执行，那么该任务通常可以得到改进。如前所述，神经网络是解决这一翻译问题的常用方法，可以使用编码器-解码器模型，也可以通过跨模态检索。当翻译在没有隐式对齐的情况下执行时，它最终会给编码器模块带来很大的负担，使其难以使用单个矢量表示正确地总结整个图像、句子或视频。   

多模态对齐面临许多困难:1)具有显式标注对齐的数据集较少;2)两种模式之间的相似度指标难以设计;3)可能存在多种可能的对齐方式，一种模式中的元素不一定在另一种模式中都有对应关系。早期关于多模对准的工作主要集中在以无监督的方式使用图形模型和动态编程技术。它依赖于手工定义的模式之间相似性的度量，或者在无监督的情况下学习它们。随着最近标签训练数据的可用性，监督学习模式之间的相似性已经成为可能。然而，无监督的技术学习联合起来对齐、转换或融合数据也变得流行起来。    

## 多模态融合   
多模态融合是多模态机器学习中最早提出的课题之一，以往的研究主要侧重于早期、晚期和混合融合方法。在技术术语中，多模态融合是将来自多种模态的信息集成在一起，并以预测结果为目标的概念:通过分类来预测一个类别(例如，快乐vs.悲伤)，或者通过回归来预测一个连续值(例如，情绪的积极性)。这是25年前工作的多模态机器学习中研究最多的方面之一。    
对多模态融合的兴趣来自于它能提供的三个主要好处。首先，能够访问观察同一现象的多种模式，可能会使预测更加可靠。AVSR社区尤其探索和利用了这一点。其次，能够访问多种模式可能允许我们捕获互补的信息——一些在单独的模式中不可见的信息。第三，当其中一种模态缺失时，多模态系统仍然可以运行，例如，当一个人不讲话时，可以从视觉信号中识别情绪。   
们将多模态融合分为两大类:不直接依赖于特定机器学习方法的模型不可知方法;以及在构建中显式处理融合的基于模型的方法，例如基于内核的方法，图形模型和神经网络。    

- 模型不可知方法     
  历史上，绝大多数多模融合都是用模型不可知论方法完成的。这种方法可以分为早期（即基于特征）、晚期（即基于决策）和混合融合。早期融合在提取特征后立即集成特征（通常只需将其表示连接起来）。另一方面，后期融合在每种模式做出决定（例如分类或回归）后执行集成。最后，混合融合结合了早期融合的输出和单个单模态预测因子。模型不可知方法的一个优点是，它们几乎可以使用任何单模态分类器或回归器来实现。
- 基于模型方法    
  虽然使用单模态机器学习方法很容易实现模型不可知的方法，但是它们最终使用的技术不是设计用来处理多模态数据的。在本节中，我们将描述用于执行多模态融合的三种方法:基于内核的方法、图形模型和神经网络。  

多模态融合是一个被广泛研究的课题，提出了许多方法来解决它，包括模型不可知方法、图形模型、多核学习和各种类型的神经网络。每种方法都有自己的优点和缺点，有些方法更适合于较小的数据集，有些方法在嘈杂的环境中性能更好。最近，神经网络已经成为处理多模态融合的一种非常流行的方法，然而图形模型和多核学习仍在使用，特别是在训练数据有限或模型可解释性很重要的任务中。    
尽管取得了这些进展，多模态融合仍然面临以下挑战:1)信号可能不是时间对齐的(可能是密集连续信号和稀疏事件);2)难以建立利用补充信息而不仅仅是补充信息的模型;3)每种模态可能在不同的时间点表现出不同的类型和不同程度的噪声。    

## 协同学习     
分类法中的最后一个多模态挑战是协同学习——通过从另一个(资源丰富的)模态中获取知识来帮助(资源贫乏的)模态建模。当其中一种模式的资源有限时(缺少带注释的数据、有噪声的输入和不可靠的标签)，它尤其重要。我们称这种挑战为共同学习，因为大多数情况下，辅助模式只在模型训练中使用，在测试期间不使用。我们根据培训资源确定了三种类型的共同学习方法:并行、非并行和混合。并行数据方法需要训练数据集，其中来自一种模式的观察直接链接到来自其他模式的观察。换句话说，当多模态观测来自相同的实例时，例如在视听语音数据集中，其中的视频和演讲样本来自同一个演讲者。相反，非并行数据方法不需要在不同模式的观测之间建立直接联系。这些方法通常通过在类别上使用重叠来实现共同学习。例如，在零镜头学习中，传统的视觉对象识别数据集通过维基百科的第二个纯文本数据集进行扩展，以提高视觉对象识别的通用性。在混合数据设置中，模式通过共享模式或数据集进行桥接。   
<div align=center><img src="..\..\image\MMML\337abafba33b58329a867ea55b2a591.jpg" width="500"></div> 

- 平行数据   
  在并行数据共同学习中，两种模式共享一组实例——带有相应视频、图像及其句子描述的音频记录。这允许两种算法利用这些数据来更好地建模模式:联合训练和表示学习。   
  协同训练是在多模态问题中只有少量的标记样本时，生成更多标记样本的过程。基本算法在每个模态中构建弱分类器，以便为未标记的数据彼此引导标签。   

- 非平行数据  
  依赖于非并行数据的方法不需要模态具有共享实例，而只需要共享类别或概念。非并行协同学习方法在学习表示时可以提供帮助，允许更好地理解语义概念，甚至可以执行不可见的对象识别。   
  迁移学习也可以在非并行数据上进行，并允许通过将信息从使用数据丰富或干净的模式构建的表示传输到数据稀缺或嘈杂的模式来学习更好的表示。这种类型的传输学习通常是通过使用协调的多模态表示来实现的  
  概念基础是指学习语义意义或概念，不仅仅是基于语言，还包括视觉、听觉、甚至是嗅觉等附加形式。虽然大多数概念学习方法都是纯语言为基础的，但人类对意义的表征不仅是我们语言暴露的产物，而且也是通过我们的感觉运动经验和感知系统而建立起来的。人类的语义知识在很大程度上依赖于感知信息，许多概念是建立在感知系统的基础上的，并非纯粹的符号。这意味着单纯从文本信息中学习语义意义可能不是最优的，并会激发使用视觉或听觉线索来为我们的语言表征奠定基础。  
  概念基础已被发现是一种有效的方法，以提高性能的一些任务。它还表明，语言和视觉(或音频)是互补的信息源，将它们组合在多模态模型中通常可以提高性能。但是，必须小心，因为接地并不总是能带来更好的性能，并且只有当接地与任务相关时才有意义-例如，使用图像进行接地以获得视觉相关概念。   
  ZSL主要有两种类型——单模态和多模态。单模态ZSL查看对象的组成部分或属性，如用于识别未听过的单词的音素，或用于预测未见的可视类的视觉属性，如颜色、大小和形状。多模zsl通过第二模态的帮助识别主模态中的对象——在第二模态中，对象已经被看到。根据定义，zsl的多模式版本是一个面临非并行数据的问题，因为所见类的重叠在模式之间是不同的。   

- 混合数据   
  在混合数据设置中，两个非并行模式由共享模式或数据集桥接。最值得注意的例子是桥接相关神经网络，它使用一个中心模态来学习存在非并行数据的协调多模态表示。    

多模态联合学习允许一种模态影响另一种模态的训练，利用跨模态的互补信息。需要注意的是，联合学习是独立于任务的，可以用于创建更好的融合、转换和对齐模型。以协同训练、多模态表示学习、概念基础和零镜头学习(zero shot learning, ZSL)等算法为例，在视觉分类、动作识别、视听语音识别和语义相似度估计等领域得到了广泛的应用。
