# 深度学习训练模板

## 一、数据处理

数据处理部分，无非是需要构建两个模块train_dataset以及train_dataloader

首先dataset可以使用两种方式进行构建

- 使用pytorch内置的库函数，但是你的原始数据集需要符合它规定的文件夹格式，如这里的ImageFolder
- 自定义，你需要继承Dataset类，并实现自己的myDataset类。具体来说，要实现三个函数，可见[__init__()与__getitem__()及__len__() - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/87786297)的解析

需要注意的是，根据数据集的文件夹格式不一样，我们往往还需要事先对其进行处理。下面代码的实例是对Stanford Dogs进行的数据处理。通过分析其数据集格式，我们需要在定义myDataset类之前先进行一定的处理，使得在实现myDataset类时，可以通过给定索引，就可以得到对应的图片及其标签（当然，也可以在实现__getitem__()时再对数据进行处理，如对图片进行剪裁等）

其次是dataloader，其主要的功能就是对传入的dataset中的数据进行batch采样，具体的参数定义参考[torch.utils.data — PyTorch 2.0 documentation](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)

```python
# https://blog.csdn.net/qq_29774003/article/details/94434745      
    train_dataset = torchvision.datasets.ImageFolder("../dataset/Stanford_Dogs_Dataset/Images/", transform=preprocess)
    # 将lable从数字转换回对应的文本
    class_name = [0]*120
    for k,v in enumerate(train_dataset.class_to_idx):
        idx = v.find('-')+1
        class_name[int(k)] = v[idx:]
    
    class myDataset(Dataset):
        def __init__(self, data, class_name):
            super().__init__()
            self.data = data
            self.class_name = class_name
        
        def __getitem__(self, index):
            img, label_idx = self.data[index]
            label = class_name[label_idx]
            return img, label
        def __len__(self):
            return len(self.data)
    
    train_dataset = myDataset(train_dataset, class_name)
    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)

# 训练时遍历
for epoch in range(NUM_EPOCHS):
        print(f"Epoch: {epoch}")
        epoch_train_loss = 0
        # 在使用pytorch构建神经网络的时候，训练过程中会在程序上方添加一句model.train()，作用是启用batch normalization和drop out
        model.train()
        start = time.time()
        for i, batch in enumerate(train_dataloader):
            img, label = batch
```

## 二、模型构建

## 三、训练

## 四、测试