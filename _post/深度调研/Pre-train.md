# 深度调研之预训练模型  
OSCAR论文的作者张磊老师在谈到大规模预训练的未来时，认为有一个值得去研究的**发展路线**   
- 从统计学习的角度来说，数据量要趋于无穷大的时候，他才能保证你的模型的收敛性以及泛化能力。因此，他觉得现在的工作还是小数据的问题，他对大规模训练和表示学习非常有信心。     
- 算法方面以及如何引入结构信息然后进到预训练的过程也是一个值得研究的方法，正如他的OSCAR工作,就是引入了物体标签到预训练过程中。该信号极大地帮助他们的模型学到更好的表示。因此，如何更好地引入预训练任务，如何引入更好的结构信息或者其他更有效的信号到学习过程中，使得更加地data-efficient。    
  

**OSCAR论文解读**   
整体来说，该篇工作利用了现存的物体检测功能，将其加入了他们的模型，这样就带来了一个tag信息（包含的是图片的一个物体的区域及其对应的标签）那么相当于他们又可以从图像角度，又可以从文本角度看待问题了。  
<div align=center><img src="..\..\image\深度调研\d7bac82068e1d3e8561d912289e00aa.jpg" width="500"></div>      
他说到，这本来是一个弱监督问题，他相当于加入了更多的监督信息，因此效果更好了。他们发现了一个好的监督信息，即引入物体检测的结果，既有图像的区域特征、也有检测的物体标签。    
最后，他还提到了一个tagging的问题，这篇论文的词表只有几百种，是否可以增加以使得更具通用性？   
CLIP工作实际中，图像的表征停留在了图像的级别，并没有进到物体的表示里面。他认为，这块可能会催生出更多的工作。   

------- 
华刚的Video Imprint中讲到，他们的实验结果不仅与sota进行了比较，还与baseline进行了比较，以此证明说，他们构建一个复杂的系统是有必要的。   
在event recounting方面没有现在的benchmark，因此在一些客观的量化指标不容易拿到的情况下，是可以采取用户调研的方式来做量化的实验。     
对于工程实验来说，通常我们会试图建立一个方法或者一个系统在某一类的任务上，在某些evaluation metric下能达到较优的性能。在写paper是，我们需要make a certain claim，而这往往是以一个scientific hypothesis的角度提出来的，即我们的模型因为做了这个工作，所以得到了提高，因此我们的实验就要围绕验证这个说话而设计。    

------
swin transformer的作者胡瀚  
追求图像和语言的统一模型，如ViT。但是它没有很好地利用视觉信号的一些特点。这里使用了滑动窗口。    
为了验证每一个设计是否是有效的，做了四个方面的比较    
在谈到论文灵感来源时，他注意到ViT的实际速度比理论上快了很多，于是他们分析原因，是刚好做了一个global的计算，因此他们抓住了这点。  
tranformer与CNN的结合   

----
Dynamic Head 袁路     
普适性   
encoder从骨干网络抽取feature    
decoder把feature转换成下游任务     
他们的dynamic head就起到了桥梁的作用     
transformer对大数据适配能力非常强   动态参数 闭环 （那它有什么缺点嘛？）    
但是CNN的平移不变性，naive transformer是不具备的    

-------   
MetaAvatar  汤思宇   
她的思路是受到一篇工作的启发，但是这篇工作的输入要求比较高，显然对于一个普通人来说无法拥有4d相机，因此她想法是降低输入的信息，即使用少量的RGBD图片就可以达到相同的效果。本质上她是使用了一个预训练模型，因此它的预训练模型看到过这些东西，因此它只需要少量的信息可能就行了    
对于他们能够处理out of disturbution，他认为是no，因为它的训练数据没有这样的data，因此不能generalize      

------    
HRNet 王井东   
首先分析任务本质，如图片分类不需要高分辨率，但是物体检测等需要。    
以前的工作resnet、densenet等其实都是学习低分辨率的表征（我觉得需要深入了解CNN、RNN、transformer的机理了）   
**使用到遥感图像分割也不错**    https://github.com/HRNet

多路之间的交互，即不同分辨率的表征的。开始的想法自然是想follow以前的工作，但是后面分析了一下本质，无非是高分辨率希望拿到其他分辨率的一个表征，因此他思考的应该是给什么操作把它连接起来就好了，因此产生了这么一个简单的网络结构。   
写论文是要从读者的角度出发，好不好理解？有没有感受到价值？   

----    
Reinforced Multi-Teacher Selection for Knowledge Distillation     
在线上部署大模型需要时间较快，因此产生了通过知识蒸馏进行模型压缩的想法    
多个教师模型训练一个学生模型，甚至可以超过教师模型，做法是给不同的教师模型分配不同的权重，以使学生模型达到最好的效果（强化学习问题框架）动态选择（当学生模型弱的时候跟弱的老师学习，强的跟强的学习）   
工程时，考虑更多参数的性价比，而不是一味的大模型   要求可解释性（即可控）    
NLP 做到优秀，挑战是常识和推理问题   Neural-symbolic    
hybird system  human+AI共同解决上面这两个问题？   

------   
R-Drop     
dropout使得training和inference有mismatch的问题   
由之前他们一篇对分词方式consistent的正则化，想到dropout是不是也可以应用    
先实验再想解释。。。。。    

-----   
Top-k learning to rank    
当别人都关注模型结构时，他把眼光放在了训练数据上     
分析用户特性：只关注第一页，top-k    
怎么找baseline?     
不陷入前人的思考陷阱，提出自己的见解    
用数学的角度看应用    




