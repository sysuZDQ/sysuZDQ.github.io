# 深度调研之预训练模型  
OSCAR论文的作者张磊老师在谈到大规模预训练的未来时，认为有一个值得去研究的**发展路线**   
- 从统计学习的角度来说，数据量要趋于无穷大的时候，他才能保证你的模型的收敛性以及泛化能力。因此，他觉得现在的工作还是小数据的问题，他对大规模训练和表示学习非常有信心。     
- 算法方面以及如何引入结构信息然后进到预训练的过程也是一个值得研究的方法，正如他的OSCAR工作,就是引入了物体标签到预训练过程中。该信号极大地帮助他们的模型学到更好的表示。因此，如何更好地引入预训练任务，如何引入更好的结构信息或者其他更有效的信号到学习过程中，使得更加地data-efficient。    
  

**OSCAR论文解读**   
整体来说，该篇工作利用了现存的物体检测功能，将其加入了他们的模型，这样就带来了一个tag信息（包含的是图片的一个物体的区域及其对应的标签）那么相当于他们又可以从图像角度，又可以从文本角度看待问题了。  
<div align=center><img src="..\..\image\深度调研\d7bac82068e1d3e8561d912289e00aa.jpg" width="500"></div>      
他说到，这本来是一个弱监督问题，他相当于加入了更多的监督信息，因此效果更好了。他们发现了一个好的监督信息，即引入物体检测的结果，既有图像的区域特征、也有检测的物体标签。    
最后，他还提到了一个tagging的问题，这篇论文的词表只有几百种，是否可以增加以使得更具通用性？   
CLIP工作实际中，图像的表征停留在了图像的级别，并没有进到物体的表示里面。他认为，这块可能会催生出更多的工作。    

