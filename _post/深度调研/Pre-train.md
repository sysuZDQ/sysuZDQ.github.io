# 深度调研之预训练模型  
OSCAR论文的作者张磊老师在谈到大规模预训练的未来时，认为有一个值得去研究的**发展路线**   
- 从统计学习的角度来说，数据量要趋于无穷大的时候，他才能保证你的模型的收敛性以及泛化能力。因此，他觉得现在的工作还是小数据的问题，他对大规模训练和表示学习非常有信心。     
- 算法方面以及如何引入结构信息然后进到预训练的过程也是一个值得研究的方法，正如他的OSCAR工作,就是引入了物体标签到预训练过程中。该信号极大地帮助他们的模型学到更好的表示。因此，如何更好地引入预训练任务，如何引入更好的结构信息或者其他更有效的信号到学习过程中，使得更加地data-efficient。    
  

**OSCAR论文解读**   
整体来说，该篇工作利用了现存的物体检测功能，将其加入了他们的模型，这样就带来了一个tag信息（包含的是图片的一个物体的区域及其对应的标签）那么相当于他们又可以从图像角度，又可以从文本角度看待问题了。  
<div align=center><img src="..\..\image\深度调研\d7bac82068e1d3e8561d912289e00aa.jpg" width="500"></div>      
他说到，这本来是一个弱监督问题，他相当于加入了更多的监督信息，因此效果更好了。他们发现了一个好的监督信息，即引入物体检测的结果，既有图像的区域特征、也有检测的物体标签。    
最后，他还提到了一个tagging的问题，这篇论文的词表只有几百种，是否可以增加以使得更具通用性？   
CLIP工作实际中，图像的表征停留在了图像的级别，并没有进到物体的表示里面。他认为，这块可能会催生出更多的工作。   

------- 
华刚的Video Imprint中讲到，他们的实验结果不仅与sota进行了比较，还与baseline进行了比较，以此证明说，他们构建一个复杂的系统是有必要的。   
在event recounting方面没有现在的benchmark，因此在一些客观的量化指标不容易拿到的情况下，是可以采取用户调研的方式来做量化的实验。     
对于工程实验来说，通常我们会试图建立一个方法或者一个系统在某一类的任务上，在某些evaluation metric下能达到较优的性能。在写paper是，我们需要make a certain claim，而这往往是以一个scientific hypothesis的角度提出来的，即我们的模型因为做了这个工作，所以得到了提高，因此我们的实验就要围绕验证这个说话而设计。    

------
swin transformer的作者胡瀚  
追求图像和语言的统一模型，如ViT。但是它没有很好地利用视觉信号的一些特点。这里使用了滑动窗口。    
为了验证每一个设计是否是有效的，做了四个方面的比较    
在谈到论文灵感来源时，他注意到ViT的实际速度比理论上快了很多，于是他们分析原因，是刚好做了一个global的计算，因此他们抓住了这点。  
tranformer与CNN的结合   

----
Dynamic Head 袁路     
普适性   
encoder从骨干网络抽取feature    
decoder把feature转换成下游任务     
他们的dynamic head就起到了桥梁的作用     
transformer对大数据适配能力非常强   动态参数 闭环 （那它有什么缺点嘛？）    
但是CNN的平移不变性，naive transformer是不具备的    

-------   
MetaAvatar  汤思宇   
她的思路是受到一篇工作的启发，但是这篇工作的输入要求比较高，显然对于一个普通人来说无法拥有4d相机，因此她想法是降低输入的信息，即使用少量的RGBD图片就可以达到相同的效果。本质上她是使用了一个预训练模型，因此它的预训练模型看到过这些东西，因此它只需要少量的信息可能就行了    
对于他们能够处理out of disturbution，他认为是no，因为它的训练数据没有这样的data，因此不能generalize      

------    
HRNet 王井东   
首先分析任务本质，如图片分类不需要高分辨率，但是物体检测等需要。    
以前的工作resnet、densenet等其实都是学习低分辨率的表征（我觉得需要深入了解CNN、RNN、transformer的机理了）   
**使用到遥感图像分割也不错**    https://github.com/HRNet

多路之间的交互，即不同分辨率的表征的。开始的想法自然是想follow以前的工作，但是后面分析了一下本质，无非是高分辨率希望拿到其他分辨率的一个表征，因此他思考的应该是给什么操作把它连接起来就好了，因此产生了这么一个简单的网络结构。   
写论文是要从读者的角度出发，好不好理解？有没有感受到价值？   

----    
Reinforced Multi-Teacher Selection for Knowledge Distillation     
在线上部署大模型需要时间较快，因此产生了通过知识蒸馏进行模型压缩的想法    
多个教师模型训练一个学生模型，甚至可以超过教师模型，做法是给不同的教师模型分配不同的权重，以使学生模型达到最好的效果（强化学习问题框架）动态选择（当学生模型弱的时候跟弱的老师学习，强的跟强的学习）   
工程时，考虑更多参数的性价比，而不是一味的大模型   要求可解释性（即可控）    
NLP 做到优秀，挑战是常识和推理问题   Neural-symbolic    
hybird system  human+AI共同解决上面这两个问题？   

------   
R-Drop     
dropout使得training和inference有mismatch的问题   
由之前他们一篇对分词方式consistent的正则化，想到dropout是不是也可以应用    
先实验再想解释。。。。。    

-----   
Top-k learning to rank    
当别人都关注模型结构时，他把眼光放在了训练数据上     
分析用户特性：只关注第一页，top-k    
怎么找baseline?     
不陷入前人的思考陷阱，提出自己的见解    
用数学的角度看应用    





----------- 
目前有三个想法     
1. 预训练模型的改进     
   1. 在预训练过程中加入**结构信息**以帮助预训练模型学习到更好的表示，具体来说，可以考虑使用现存的一些方法得到监督信息，然后将该信息加进去辅助模型的预训练
   2. 在**词表**里做文章
   3. 如果能同时从图像和文本**两个角度**看待数据，那么得到的表示会更全面。具体来说，应该是从两个方面设计对应的损失函数
   4. 学习更深层的表征，如CLIP学习到的只是表征其实只是图像级别的
   5. 现有想法的话，主要可以从模型结构、数据利用方向入手
   6. 解决网络深而带来的梯度问题，但是我想深的网络我也做不了吧。。。不过倒是可以在一些没那么深的网络说明我这个方法的有效性就好了
   7. 好像自监督一般用于NLP，那么将其用于CV行不行？
   8. 可以参考本科论文的思想，即多方联合训练
   9. NLP中，神经网络的输入往往是word embedding，因此可以考虑优化词嵌入方式
   10. 有些工作发现，模型中的一些参数是不起作用的，也就是说去掉这部分参数对性能没有影响，可以去探寻到底那些参数起了作用，作用是啥
   11. prompt，21年的时候大多数人已经搞不起军备竞赛了，开始利用Prompt去研究如何在最低的精调成本下用上大模型
   12. 目标函数工程，本质上是调整预训练阶段，使得模型能够适配一些下游任务，如文本生成
   13. 
2. 多模态预训练模型的研究
3. 将NLP与CV界领先的方法进行相互迁移  
4. 抓住现有一些优秀工作的痛点进行改进
   1. 如swim transformer使用了CNN中的滑动窗口将视觉信号利用了起来
   2. 如MetaAvatar就是以更低要求的输入到达相同的效果
   3. 追求时间和内存效率，例如一些模型在线上进行部署时需要满足一定的时间要求，因此可以从提高现有模型的时间或内存效率同时性能基本保持不变的思路出发
   4. 追求可解释性，例如工程界对于一些部署的模型是可控时，就必须要满足可解释性
   5. 增强现有模型的性能，如GPT3不仅回答问题，而且还把回答的引用返回出来
5. 取长补短，将每种模型的优点抽出来，弥补另一个模型的缺点  
   1. 如CNN的平移不变性，transformer是不具备的
6. 对现有学习流程进行改进  
   1. 如知识蒸馏，一般是一个教师模型指导一个学生模型。改进做法是多个教师模型指导一个学生模型，并且是可以动态调整其权重的

7. Hybird System
   1. human+AI?对于一些困难的问题，如NLP中的常识和推理，我们现在无法通过纯AI方法进行解决，那么是不是可以通过一部分人工协助AI以达到能解决该问题的能力？
8. 从数据出发  
   1. 通过对训练数据的处理，使得其更适配下游任务，从而获得更好的性能。
   2. 现在网络世界产生的数据虽然很多，但是大部分我们并不能利用进去，因此如何将这些数据利用起来是一个值得思考的点
9. 模型中的基础组件的改进
    1. 如R-Drop一文中就针对了dropout函数进行了分析，解决了使用了dropout之后training和inference之间mismatch的问题
10. 将数学应用到深度学习中
    1. 这属于对一些数学原理十分了解才能迁移过来的想法了
11. 新兴的研究方向
    1. Neural-Symbolic：将原本对立的连接主义和符号主义结合的一个新兴研究方向   https://zhuanlan.zhihu.com/p/463013878
    2. Instruction tuning     
    3. https://mp.weixin.qq.com/s?__biz=MzAxMTk4NDkwNw==&mid=2247488283&idx=1&sn=6323ec0585df7c723795e3bfab38cdc5&chksm=9bb99a7facce136946b48aa07da7e4508b388b557c31bbf0dcbf334cbf74010d0d85792a300f&token=337802366&lang=zh_CN#rd

12. 统一！
    1. 例如统一下游任务，数据很难获取，不希望这些数据训练出来的模型仅仅解决一些任务
    2. 






