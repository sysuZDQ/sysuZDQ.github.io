## 摘要
提出了一个模型Omni-perception Pre-Trainer(OPT)，通过利用文本、图像、语音数据实现了跨模态的理解和生成！      
OPT使用的是encoder-decoder框架，包括了    
- 三个singel-modal encoders：分别编码三种模态
- 一个cross-modal encoder：编码三种模态的联系
- 两个cross-modal decoders：通过自回归的方式分别生成文本和图像

<div align=center><img src="..\深度调研\8bf0c376f9f4541be06c019131815e2b_2_Figure_1.png" width="500"></div>

在预训练任务方面，使用了三种数据粒度的任务
- token-level:predicts the semantics of masked tokens given the unmasked inputs
- modality-level: two generative tasks, i.e., denoising text reconstruction and denoising image reconstruction and  randomly masks out the whole inputs from any one or two of the three modalities
- sample-level: learns the alignment among the three modalities corresponding to the same sample
  
数据集上，使用了Open Images的image-text-audio triplets     

## 介绍   
这项工作的动机是 *a machine with human-like intelligence should be trained on multi-modal resources, to develop the both capabilities of cross-modal understanding and generation.*    
先前的多模态预训练工作存在一个问题： *they are proposed to specialize in certain types of cross-modal understanding or generation tasks, and cannot establish general knowledge for unified processing.*例如ViLBERT、VisualBERT只做理解任务，而DALL-E只能做生成任务。    
为了验证实验结果，做了大量的下游任务，包括 *cross-modal retrieval, multi-modal classification, visual question answering, cross-modal text generation (including speech recognition and visual captioning), and text-to-image generation*    
总的来说，OPT的创新点有
-  OPT is the first pre-trained model that connects the three modalities of text, vision, and audio, and is endowed with the both capacities of cross-modal understanding and generation.
-   OPT learns to align and translate among different modalities with the token-, modality-, and samplelevel pretext tasks.
-    OPT can effectively adapt to and perform competitively on a series of cross-modal understanding and generation downstream tasks with parial or all modalities as inputs.   

## 相关工作   
### Single-Modal Pre-Training
- NLP：成功的关键在于Transformer架构的使用和一些在大规模语料库上的预训练任务，一些优秀工作有GPT,BERT,XLNet,MASS,UniLM,BART，一个想法是参考这些工作的思路，运用到我们这个三模态预训练模型上。一个需要考虑的问题是，如果直接迁移肯定有gap，那么我们需要解决这个问题
- CV：最近来说，对比学习是一个值得深入的方向，相关工作有SimCLR,MoCo,BYOL
- Audio and Speech；这块我不是很了解 pre-training has focused on emotion recognition [24], speaker identification [32], phoneme discrimination [39, 27], transferring ASR representations from one language to another [17], unsupervised representations learning for speech [35], audio representation learning [43].   

### Mutil-Modal Pre-Training
以前的多模态预训练都是VLP，主要可以分为两种类型
- 单流： VisualBERT [22], UNITER [5], Unicoder-VL [20] and VL-BERT [38]
- 双流： ViLBERT [25] and LXMERT [40]

因此，OPT是第一个三模态预训练模型

## 模型架构
## 预训练任务
## 实验
## 讨论
论文提出了五点值得深究的地方
- 收集三模态数据并不容易
- 如何在 un-paired or partial-modality data的情况下，也就是某些模态缺失的情况下有效地训练模型（个人觉得这里可以参考先前一些VLP中的解决方案
- 在预训练过程中如何利用好知识（这里是不是可以加入诸如知识图谱这一类的外部知识
- 通过人类的反馈和交互来进一步学习，也就是强化学习
- 开发更多的应用，这里指的是论文中没有做的一些应用，如 generate raw audio (conditioned on language, image, or another audio), image editing and image to image translation, video editing and generation under language/audio instructions etc.