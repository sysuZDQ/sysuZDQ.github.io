# 论文一
## 初步想法
多模态：图像+文本   
方法：对比学习+prompt+引入外部知识

## 步骤
1. 确定方向：多模态预训练之后用于下游的检索任务。
2. 确定问题：
   1. （现在基于图片的搜索都是根据图像的相似性来检索的，本质上并没有学习到图像的语义特征？）
   2. （目前image2text的效果怎么样？是不是给一个图片能准确输出它的语义，但是我觉得就算如此他一般是指的人在钓鱼，而不是特定的人，比如特朗普在钓鱼）
   3. （另一方面，text2image的发展如何，能不能做到给定一句话，输出想要的图片？测试了一下，好像它是按照网页中文本的信息返回的，根本就不涉及图片的理解）
   4. （输入一个图片+几个关键字进行检索会不会是一个好的方式？）
   5. （试了一下百度识图，发现它识别的粒度较粗，显然他不能看到我照片里的Redmi文字，所以返回的是较为相似的苹果电脑）
   6. （当有多个物体的时候，它应该是定位到最主体的物体进行检索）

3. 确定思路：大致想法是使用[对比学习](https://zhuanlan.zhihu.com/p/141172794)进行自监督学习，难点在于如何构建正负样本。然后引入外部知识如知识图谱以增加其性能，因为直观上说模型知道的东西更多了。最后，我们使用prompt使得下游任务适应预训练，而不是像pretrain-finetuning一样需要在预训练阶段构建适配下游任务的预训练任务。
4. 确定方法：具体公式为........（使用数学思想、借鉴现有的做法）
5. 实验验证：数据集、基线系统、评价指标
6. 撰写论文