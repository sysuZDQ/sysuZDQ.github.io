# Prompt  
本文基于2021年的一篇综述论文[Pre-train, Prompt, and Predict: A Systematic Survey of
Prompting Methods in Natural Language Processing](https://arxiv.org/pdf/2107.13586v1.pdf)进行分析与研究。   
[中文翻译](https://zhuanlan.zhihu.com/p/411341801)    
[论文主页](http://pretrain.nlpedia.ai/)

-----  
本文调查并组织了自然语言处理中的一个新范式的研究工作，我们称之为 "基于提示的学习"。与传统的监督学习不同的是，**传统的监督学习**是训练一个模型来接受输入$x$并预测输出$y$的$P(y|x)$，而**基于提示的学习**是基于语言模型，直接对文本的概率进行建模。为了使用这些模型来执行预测任务，原始输入$x$被使用模板修改成一个文本字符串提示$x'$，其中有一些未填充的槽，然后语言模型被用来概率性地填充未填充的信息，得到一个最终的字符串$\hat x$，从中可以得出最终的输出$y$。这个框架是强大而有吸引力的，原因有很多：它允许语言模型在大量的原始文本上进行预训练，通过定义一个新的提示函数，该模型能够进行*few-shot*甚至*zero-shot*的学习，以适应只有少数或没有标注数据的新场景。在本文中，我们介绍了这种有前途的范式的基本原理，描述了一套统一的数学符号，可以涵盖各种现有的工作，并沿着几个维度组织现有的工作，例如预训练的模型、提示和微调策略的选择。 

----
## 一 NLP的两场巨变   
**特征工程**：在完全监督学习时期，NLP研究人员或工程师利用他们的领域知识来定义和提取原始数据中的突出特征，为模型提供适当的归纳偏差以从这些有限数据中学习。  

**神经网络**：随着用于NLP的神经网络模型的出现，突出的特征被与模型本身的训练共同学习，因此重点转移到了架构工程上，在这里，归纳偏差是通过设计一个有利于学习这些特征的合适的网络架构来提供的。   

**预训练与微调**：从2017-2019年，NLP模型的学习发生了巨大的变化，这种完全监督的范式现在发挥的作用越来越小。具体来说，标准转向了预训练和微调范式。在这个范式中，一个具有固定架构的模型被预训练为语言模型（LM），预测观察到的文本数据的概率。由于训练LM所需的原始文本数据大量存在，这些LM可以在大型数据集上进行训练，在此过程中学习它所建模的语言的强大通用特征。然后，上述预训练的LM将通过引入额外的参数和使用特定任务的目标函数进行微调来适应不同的下游任务。在这个范式中，重点主要转向目标工程，设计在预训练和微调阶段都使用的训练目标。    

**预训练、提示和预测**：在这种模式下，不是通过客观工程使预训练的LM适应下游任务，而是在文本提示的帮助下，重新制定下游任务，使其看起来更像原始LM训练期间解决的任务。这种方法的优点是，给定一套适当的提示，以完全无监督的方式训练的单一LM可以用来解决大量的任务。然而，与大多数概念上诱人的前景一样，有一个问题--这种方法引入了提示工程的必要性，即找到最合适的提示，让LM解决手头的任务。
<div align=center><img src="..\image\prompt\09af0172b7ded7a8da41f1f323bf7a8.jpg" width="500"></div>    


## 二 提示学习的公式描述   
首先看一个例子以便让我们对提示学习有一个直观的印象。  
<div align=center><img src="..\image\prompt\a03ac6a133d660a5e6fb7c0e67888d5.jpg" width="500"></div>    
可以看到，要完成一个提示学习，我们需要经过以下三个步骤        

- 附加提示    
  即将输入文本$s$修改为$x'=f_{prompt}(x)$，该函数包括两个过程     
  - Apply a template, which is a textual string that has two slots: an input slot $[X]$ for input $x$ and an answer slot
$[Z]$ for an intermediate generated answer text $z$ that will later be mapped into $y$.
  - Fill slot $[X]$ with the input text $x$.     
  
  下面给出常用的提示模板  
  <div align=center><img src="..\image\prompt\90caf5d0d6f500a72627f255500934d.jpg" width="500"></div>   

- 答案搜索   
  寻找最高分的文本$\hat z$，使LM的得分最大化。下面的搜索函数可以是搜索最高分输出的*argmax*搜索，也可以是按照LM的概率分布随机生成输出的*sampling*。  
  $$  \hat z=\mathop{search}\limits_{z \in Z}P(f_{fill}(x',z); \Theta)  $$
- 答案映射   
  我们想从最高分的答案$\hat z$到最高分的输出$\hat y$，这在某些情况下是很简单的，因为答案本身就是输出（如翻译等语言生成任务）。但也有其他情况，多个答案可能导致相同的输出。例如，人们可能使用多个不同的带感情色彩的词（如 "优秀"、"美妙"、"精彩"）来代表一个类别（如 "++"），在这种情况下，有必要在搜索到的答案和输出值之间建立一个映射。   

现在我们有了基本的数学公式描述，接下来我们将阐述提示方法中的一些基本设计考虑，包括预训练模型的选择、提示工程、答案工程、拓展范式、基于提示的训练策略，下面先给出一张统计表。
<div align=center><img src="..\image\prompt\aae74b59f62dde04f46cc13aa7f5455.jpg" width="500"></div>    

## 三 预训练语言模型    
在本章中，我们提出了对各种预训练的LM的系统性看法，即（i）以更系统的方式沿着各种轴线组织它们，（ii）特别关注对提示方法突出的方面。   
下面给出一张预训练模型的总结表。  
<div align=center><img src="..\image\prompt\d7fb70b48a8bd3427559de4007421c6.jpg" width="500"></div>    
下面我们将从四个方面对预训练模型进行分析。    

- 训练目标   
  预训练的LM的主要训练目标几乎无一例外地包括某种预测文本$x$的概率的目标。    
  Standard Language Model (SLM) 的目标正是如此，训练模型以优化训练语料库中文本的概率$P(x)$。在这些情况下，文本通常以自回归的方式进行预测，每次预测序列中的token。这通常是从左到右进行的，但也可以按其他顺序进行。     
  标准语言模型目标的一个流行的替代方法是降噪目标，它对输入句子应用一些降噪函数$\hat x = f_{noise}(x)$，然后试图在这个降噪文本$P（x|\hat x）$的情况下预测原始输入句子。这些目标有两种常见的形式。   
  - Corrupted Text Reconstruction (CTR)：这些目标通过仅对输入句子的噪声部分计算损失，将处理后的文本恢复到未损坏的状态。
  - Full Text Reconstruction (FTR)：这些目标通过计算整个输入文本的损失来重构文本，无论其是否经过噪声处理    

  预训练的LM的主要训练目标在确定其对特定提示任务的适用性方面起着重要作用。例如，从左到右的自回归LM可能特别适合于前缀提示，而重建目标可能更适合于cloze提示。此外，用标准的LM和FTR目标训练的模型可能更适合于有关文本生成的任务，而其他任务，如分类，可以用这些目标中的任何一个训练的模型来制定。除了上述主要的训练目标外，还设计了一些辅助目标来进一步提高模型执行某些种类的下游任务的能力。我们在下表中列出了一些常用的辅助目标。
  <div align=center><img src="..\image\prompt\68ede155d7a22396b0981225548c6c0.jpg" width="500"></div>      

- 噪声功能   
  在基于重建的训练目标中，应用于获得噪声文本$\hat x$的特定类型的损坏对学习算法的功效有影响。此外，可以通过控制噪声的类型来纳入先验知识，例如，噪声可以集中在一个句子的实体上，这使得我们可以学习一个预训练好的模型，对实体的预测性能特别高。下表给出几种噪声函数。值得注意的是，下面给出的是NLP的噪声函数，我们也可以思考一下如何映射到CV领域中。   
  <div align=center><img src="..\image\prompt\4056fa948a3bad9efdfbd1fef5126d3.jpg" width="500"></div>    
- 表示的方向性    
  在理解预训练的LM以及它们之间的区别时，最后一个重要因素是计算表示的方向性。一般来说，有两种广泛使用的方法来计算这种表示。    
  - Left-to-Right 
  - Bidirectional
- 典型的预训练模型  
  我们介绍了四种流行的预训练方法，由目标、噪声函数和方向性的不同组合产生。下面先给出两张总结表。
    <div align=center><img src="..\image\prompt\32f3b6f6154f5fed566bbbe9a767e94.jpg" width="500"></div> 
     <div align=center><img src="..\image\prompt\5ef7dff9b2b1044fadf88df806f2648.jpg" width="500"></div> 

  -  Left-to-Right Language Model
  -  Masked Language Models
  -  Prefix Language Model
  -  Encoder-decoder    

## 四 提示工程   
提示工程是创建一个提示函数$f_{prompt}(x)$的过程，该函数能在下游任务中产生最有效的表现。在以前的许多工作中，这涉及到提示模板工程，即由人类工程师或算法为模型预期执行的每项任务寻找最佳模板。如图1的 "提示工程 "部分所示，人们必须首先考虑提示的形状，然后决定是采取人工还是自动的方法来创建所需形状的提示。    
- 提示形式    
  有两种主要的提示方式，*cloze prompts*，即填补文本字符串的空白，以及*prefix prompts*，即延续字符串的前缀。选择哪一种，既取决于任务，也取决于用于解决该任务的模型。一般来说，对于有关生成的任务，或正在使用标准的自回归LM解决的任务，前缀提示往往更有利，因为它们与模型的从左到右的性质很好地融合。对于使用mask式LM解决的任务，cloze提示很适合，因为它们与预训练任务的形式非常接近。全文重构模型的用途更广，既可以使用cloze提示，也可以使用前缀提示。    
- 手工模板工程   
  也许创建提示的最自然方式是根据人类的手动创建直观的模板。  
- 自动模板学习  
  虽然人工筛选模板的策略很直观，而且确实可以在一定程度上解决各种任务，但这种方法也有几个问题。(1）创建和实验这些提示是一门艺术，需要时间和经验，特别是对于一些复杂的任务，如语义解析；（2）即使是有经验的提示设计者也可能无法手工发现最佳提示。  
  为了解决这些问题，人们提出了一些方法来实现模板设计过程的自动化。特别是，自动诱导的提示可以进一步分为**离散提示和连续提示**，前者的提示是一个实际的文本字符串，后者的提示则是直接在基础LM的嵌入空间中描述。  
  另一个不相关的设计考虑是提示函数$f_{prompt}(x)$是静态的，对每个输入使用基本相同的提示模板，还是动态的，为每个输入生成一个自定义的模板。**静态和动态策略**都被用于不同种类的离散和连续提示，我们将在下面提到。
    - 离散提示  
  关于发现离散提示（又称硬提示）的工作会自动搜索在离散空间中描述的模板，通常对应于自然语言短语。我们在下文中详细介绍了为此提出的几种方法。  
        - Prompt Mining
        - Prompt Paraphrasing
        - Gradient-based Search
        - Prompt Generation
        - Prompt Scoring
    - 连续提示    
  因为构建提示的目的是找到一种能让LM有效执行任务的方法，而不是供人使用，所以没有必要将提示限定为人类可理解的自然语言。正因为如此，还有一些研究连续提示（又称软提示）的方法，直接在模型的嵌入空间中进行提示。具体来说，连续提示消除了两个约束。(1) 放宽模板词嵌入是自然语言（如英语）词嵌入的限制。(2)取消了模板由预训练的LM的参数决定的限制。相反，模板有自己的参数，可以根据下游任务的训练数据进行调整。我们在下面强调几个有代表性的方法。    
        - Prefix Tuning
        - Tuning Initialized with Discrete Prompts
        - Hard-Soft Prompt Hybird Tuning   

## 五 答案工程   
与为提示方法设计适当输入的提示工程相比，答案工程的目的是寻找答案空间Z和与原始输出Y的映射，从而形成有效的预测模型。图1的 "答案工程 "部分说明了执行答案工程时必须考虑的两个方面：决定答案形式和选择答案设计方法。   
- 答案形式
  答案的形式表示其粒度。在实践中，如何选择可接受答案的形状取决于我们想要执行的任务。   
   - Tokens: One of the tokens in the pre-trained LM’s vocabulary, or a subset of the vocabulary.
   - Span: A short multi-token span. These are usually used together with cloze prompts.  
   - Sentence: A sentence or document. These are commonly used with prefix prompts.    
 - 答案空间设计方法  
    - 人工设计   
  在人工设计中，潜在答案的空间Z和它与Y的映射是由感兴趣的系统或基准设计者人工筛选的。有许多策略可以用来进行这种设计。     
      - 无约束空间
      - 受限空间   
    - 离散答案搜索    
        - 答案解析
        - 先剪枝再搜索
        - 标签分解  
    - 连续的答案搜索    


## 六 多提示学习    
下面先给出一些具有代表性的多提示学习方法    
<div align=center><img src="..\image\prompt\dd0a644926cec418f4a21ed6d61f76f.jpg" width="500"></div> 

- Prompt Ensembling    
  提示集合是指在推理时间使用多个未回答的提示输入来进行预测的过程。图4-(a)中显示了一个例子。这种提示集合可以（1）利用不同提示的互补优势，（2）减轻提示工程的成本，因为选择一个表现最好的提示是具有挑战性的，（3）稳定下游任务的性能。下面是组合的方法    
  - Uniform averaging
  - Weighted averaging
  - Majority voting
  - Knowledge distillation
  - Prompt ensembling for text generation 
- Prompt Augmentation   
提示增强，有时也被称为演示学习，提供了一些额外的回答提示，可以用来演示LM应该如何提供输入$x$的实际提示实例的答案。日本的首都是东京。中国的首都是$[Z]$"。另一个执行两个数字相加的例子可以在图4-（b）中找到。这些寥寥无几的演示利用了强大的语言模型学习重复模式的能力。     
虽然提示增强的想法很简单，但有几个方面使它具有挑战性。(1) 样本选择：如何选择最有效的例子？(2) 样本排序。如何根据提示对所选的例子进行排序？   
- Prompt Composition     
  对于那些可组合的任务，可以基于更基本的子任务进行组合，我们也可以进行提示组合，使用多个子提示，每个子提示用于一个子任务，然后基于这些子提示定义一个复合提示。这个过程在图4-(c)中得到了说明。例如，在关系抽取任务中，其目的是提取两个实体的关系，我们可以将任务分解为几个子任务，包括识别实体的特征和对实体之间的关系进行分类。     
- Prompt Decomposition    
  对于需要对一个样本进行多种预测的任务（如序列标注），直接对整个输入文本x定义一个整体提示是具有挑战性的。解决这个问题的一个直观方法是将整体提示分解为不同的子提示，然后分别回答每个子提示。图4-(d)以命名实体识别任务为例说明了这一想法，该任务旨在识别输入句中的所有命名实体。在这种情况下，输入将首先被转换为一组文本跨度，然后模型可以被提示预测每个跨度的实体类型（包括 "非实体"）。由于跨度很大，要同时预测所有的跨度类型并不容易，所以可以为每个跨度创建不同的提示并分别进行预测。     

## 七 提示方法的训练策略   
- 训练设置  
  在许多情况下，提示方法可以在不对下行任务的LM进行任何明确训练的情况下使用，只需将**已经训练好**的预测文本概率$P(x)$的LM，按原样应用于填补为指定任务而定义的cloze或前缀提示。这在传统上被称为*zero-shot*设置，因为感兴趣的任务的训练数据为零。   
  然而，也有一些方法使用训练数据来训练模型，与提示方法相配合。这些方法包括全数据学习，即用相当多的训练例子来训练模型，或者是少数几个例子的学习，即用非常少的例子来训练模型。提示方法在后一种情况下特别有用，因为通常没有足够的训练例子来完全说明所需的行为，因此使用提示将模型推向正确的方向是特别有效的。    
  需要注意的一点是，对于第4节中描述的许多提示工程方法，虽然标注的训练样本没有明确用于下游任务模型的训练，但它们经常被用于下游任务将使用的提示的构建或验证。正如Perez等人（2021）所指出的，就下游任务而言，这可以说不是真正的zero-shot学习。   

- 参数更新方法  
  在基于提示的下游任务学习中，通常有两类参数，即来自（1）预训练的模型和（2）提示的参数。哪一部分参数应该被更新是一个重要的设计决定，这可能导致不同场景下的不同适用程度。我们总结了五种优化策略（如表6所示），基于（i）是否优化基础LM的参数，（ii）是否有额外的提示相关参数，（iii）如果有额外的提示相关参数，这些参数是否被微调。    
  <div align=center><img src="..\image\prompt\7c38a3cf6a5f119e8d3c511c557155f.jpg" width="500"></div> 

  - Promptless Fine-tuning   
     - 优点。简单性，不需要及时设计。调整所有的LM参数可以使模型适应更大的训练数据集。

    - 缺点。LM可能过拟合或不能在较小的数据集上稳定地学习。
  - Tuning-free Prompting     
    - 优点。效率高，没有参数更新过程。没有灾难性的遗忘，因为LM参数保持固定。适用于zero-shot的设置。

    - 缺点。因为提示是提供任务规范的唯一方法，为了达到高精确度，必须进行大量的工程。特别是在上下文学习环境中，提供许多有答案的提示在测试时可能会很慢，因此不能轻易使用大型训练数据集。
  - Fixed-LM Prompt Tuning    
    - 优点。与无优化提示类似，它可以保留LMs中的知识，并适用于few-shot的情况。通常比无优化提示的精确度高。

    - 缺点。不适用于zero-shot的场景。虽然在少数情况下有效，但在大数据环境下的表现力是有限的。通过选择超参数或种子提示的提示工程是必要的。提示通常不是人类可以解释或操纵的。
  - Fixed-prompt LM Tuning     
     - 优点。提示或答案工程更完整地规定了任务，允许更有效的学习，特别是在few-shot情况下。

     - 缺点。仍然需要提示或答案工程，尽管可能不如没有提示时那么多。对一个下游任务进行微调的LM可能对另一个任务无效。
  - Prompt+LM Tuning     
      - 优点。这是最有表现力的方法，可能适用于高数据量的环境。

      - 缺点。需要训练和存储模型的所有参数。可能对小数据集过拟合。


## 八 应用   
在前几节中，我们从方法本身的机制的角度来研究提示方法。在本节中，我们更倾向于从它们被应用于哪些应用的角度来组织提示方法。我们在表7-8中列出了这些应用。   
<div align=center><img src="..\image\prompt\71e8e5aafcf3c4bd258efe74dfb250d.jpg" width="500"></div> 
<div align=center><img src="..\image\prompt\0d1f30bc93090352eae3ce604fdd019.jpg" width="500"></div>   

- 知识探测
- 基于分类的任务
- 信息提取
- NLP中的“推理”
- 问答任务
- 文本生成
- 文本生成的自动评估
- 多模态学习
- 元应用  
最后，给出一些数据集以及现有的手工设计的常用提示语  
<div align=center><img src="..\image\prompt\2f6fd78401cad81f50473df620fcc92.jpg" width="500"></div>
<div align=center><img src="..\image\prompt\9311c5ba8b663168b1494c377ecf81a.jpg" width="500"></div>    


## 九 与提示学习有关的主题  
基于提示的学习的本质是什么，它与其他学习方法有什么关系？在本节中，我们将提示性学习与其他类似的学习方法联系起来。   
- Ensemble Learning
- Few-shot Learning
- Large-context Learning
- Query Reformulation
- QA-based Task Formulation
- Controlled Generation
- Supervised Attention
- Data Augmentation   

## 十 挑战    
- 提示性设计   
  **分类和生成以外的任务** 大多数关于基于提示的学习的现有工作都围绕着文本分类或基于生成的任务。对信息提取和文本分析任务的应用讨论得较少，主要是因为提示的设计不太直接。我们预计，在未来将提示方法应用于这些任务时，将需要重新制定这些任务，以便它们可以用基于分类或文本生成的方法来解决，或者执行有效的答案工程，以适当的文本格式来表达结构化的输出。   
  **用结构化信息进行提示** 在许多NLP任务中，输入被赋予了某种结构，如树、图、表或关系结构。如何在提示或回答工程中最好地表达这些结构是一个重大挑战。现有的工作（Chen等人，2021b）迈出了一步，使提示语带有额外的标记来编码词汇信息，如实体标记。Aghajanyan等人（2021）提出了基于超文本标记语言的结构化提示，用于更细化的网络文本生成。然而，除此之外，向更复杂的结构品种发展在很大程度上还没有被探索，这也是一个潜在的有趣研究领域。

- 答案工程  
  **多类和长答案分类任务** 对于基于分类的任务，答案工程有两个主要挑战。(a) 当有太多的类时，如何选择一个合适的答案空间成为一个困难的组合优化问题。(b) 当使用多token答案时，尽管已经提出了一些多token解码方法，但如何使用LM对多token进行最佳解码仍是未知数（Jiang等人，2020a）。  
  **生成任务的多个答案** 对于文本生成任务，合格的答案在语义上可以是等同的，但在句法上是不同的。到目前为止，几乎所有的工作都是使用仅依靠单一答案的文本生成的提示学习，只有少数例外（Jiang等人，2020c）。如何更好地指导有多个参考答案的学习过程仍然是一个基本开放的研究问题。     

- 调试策略的选择   
  正如第7节中所讨论的，有相当多的方法来调整提示、LM或两者的参数。然而，考虑到这一研究领域的新生阶段，我们仍然缺乏对这些方法之间权衡的系统理解。该领域可以从系统性的探索中受益，比如在预训练和微调范式中进行的关于这些不同策略之间的权衡（Peters等人，2019）。    

- 多重提示学习   
  **提示集合** 在提示集合方法中，空间和时间的复杂性随着我们考虑更多的提示而增加。如何从不同的提示中提炼出知识仍然没有得到充分的探索。Schick和Schu¨tze（2020, 2021a,b）使用一个集合模型来注释一个大型数据集，以提炼来自多个提示的知识。此外，如何选择有集成模型价值的提示语也没有得到充分的探讨。对于文本生成任务来说，提示语集合学习的研究到目前为止还没有进行，这可能是因为文本生成中的集合学习本身相对复杂。为了弥补这个问题，最近提出的一些神经集合方法，如Refactor（Liu等人，2021c）可以考虑作为文本生成任务中提示集合的方法。   
  **提示语的构成和分解** 提示语的构成和分解都是为了通过引入多个子提示语来分解复杂任务输入的难度。在实践中，如何在它们之间做出一个好的选择是一个关键的步。根据经验，对于那些token（Ma and Hovy, 2016）或跨度（Fu et al., 2021）预测任务（如NER），可以考虑提示分解，而对于那些跨度关系预测（Lee et al., 2017）任务（如实体核心推理），提示构成将是一个更好的选择。在未来，可以在更多的场景中探索去掉/组合的一般思路。   
  **提示性增强** 现有的提示性增强方法受到输入长度的限制，也就是说，向输入输入太多的演示是不可行的。因此，如何选择信息量大的演示，并将其适当排序是一个有趣但具有挑战性的问题（Kumar和Talukdar, 2021）。   
  **提示共享** 上述所有的考虑都是指提示在单一任务、领域或语言中的应用。我们也可以考虑提示的共享，即提示学习被应用于多个任务、领域或语言。可能出现的一些关键问题包括如何为不同的任务设计单独的提示，以及如何调节它们之间的相互作用。到目前为止，这个领域还没有被探索过。图5展示了一个简单的多任务多提示学习策略，其中提示模板是部分共享的。   

- 预训练模型的选择  
由于有大量的预训练模型可供选择（见第3节），如何选择它们以更好地利用基于提示的学习是一个有趣而困难的问题。尽管我们已经从概念上介绍了（第3.4节）如何为不同的NLP任务选择不同的预训练模型范式，但对于基于提示的学习为不同的预训练LM带来的好处，几乎没有系统的比较。   

- 提示性的经验和理论分析   
  尽管它们在许多场景中取得了成功，但基于提示的学习的理论分析和保证却很少。Wei等人(2021)表明，软提示优化可以放松下游恢复(即恢复下游任务的真实标签。)所需的非退化性假设(每个标注的生成概率是线性独立的)，使其更容易提取任务的特定信息。Saunshi等人（2021）验证了文本分类任务可以被重新表述为句子完成任务，从而使语言模型成为有意义的预训练任务。Scao和Rush（2021）根据经验表明，在不同的分类任务中，提示往往平均价值100多个数据点。   

- 提示语的可迁移性   
  了解提示对模型的特定程度和提高提示的可迁移性也是重要的课题。(Perez等人，2021年）表明，在微调的few-shot学习情景下（人们有较大的验证集来选择提示语）选择的提示语在类似规模的模型中具有良好的概括性，而在真正的few-shot学习情景下（人们只有few-shot训练样本）选择的提示语在类似规模的模型中的概括性不如前者的设置有效。当两种情况下的模型大小都很不一样时，其可迁移性就很差。   

- 不同范式的结合   
  值得注意的是，提示范式的大部分成功是建立在为预训练和微调范式开发的预训练模型之上的，如BERT。然而，对后者有效的预训练方法是否可以原封不动地适用于前者，或者我们可以完全重新思考我们的预训练方法，以进一步提高准确性或对基于提示的学习的适用性？这是一个重要的研究问题，文献中没有广泛涉及。    

- 提示方法的校准   
  校准（Gleser, 1996）指的是模型进行良好概率预测的能力。当使用预训练的LM（如BART）的生成概率来预测答案时，我们需要小心，因为概率分布通常没有经过良好的校准。Jiang等人（2020b）观察到预训练模型（如BART、T5、GPT-2）在QA任务上的概率是经过良好校准的。Zhao等人（2021年）发现了三个隐患（多数标签偏差、回顾性偏差和共同标注偏差），导致预训练的LM在提供有答案的提示时偏差某些答案。例如，如果最后回答的提示有一个积极的标签，那么这将使模型偏差预测积极的词语。为了克服这些缺陷，Zhao等人（2021）首先使用无语境输入（例如，提示是 "输入。不合格的演技。感情。Negative/n 输入。美丽的电影。Sentiment: Positive\n Input: 不适用。Sentiment:"）得到初始概率分布P0，然后他们使用真正的输入（例如，提示将是 "输入。不合格的演技。Sentiment: Negative/n 输入。美丽的电影。Sentiment: Positive\n Input: Amazing. Sentiment："），得到概率分布P1。最后，这两个分布可以用来得到一个校准的生成概率分布。然而，这种方法有两个缺点。(1)它伴随着寻找适当的无语境输入的开销（例如，是否使用 "N/A "或 "None"）和(2)底层预训练的LM的概率分布仍然没有被标定。       
  即使我们有一个校准的概率分布，但当我们假设一个输入的单一glod答案时，我们也需要小心。这是因为同一目标的所有表面形式将竞争有限的概率质量（Holtzman等人，2021）。例如，如果我们认为glod答案是 "漩涡浴"，它的生成概率通常会很低，因为 "浴缸 "这个词有相同的含义，它将占据大量的概率质量。为了解决这个问题，我们可以(i)执行答案工程，使用转述方法构建一个全面的glod答案集（§5.2.2），或者(ii)根据一个词在上下文中的先验可能性来校准它的概率（Holtzman等人，2021）。

## 十一 元分析   
在本节中，我们旨在通过对不同维度的现有研究工作进行元分析，对现有的提示方法的研究提供一个定量的鸟瞰图。   
<div align=center><img src="..\image\prompt\1cfcf72770fed1c882615173855c2d9.jpg" width="500"></div>    
我们还计算了基于提示的论文在不同维度上的数量。   
<div align=center><img src="..\image\prompt\11fd875170c9d519ab635d095592861.jpg" width="500"></div>     
