MILAN: Masked Image Pretraining on Language Assisted Representation   
近年来，基于自注意的Transformer模型一直是计算机视觉领域的研究热点.其卓越的模型质量在很大程度上依赖于超大规模的标记图像数据.为了减少对大规模标记图像数据的依赖，基于重构的掩蔽自动编码器得到了广泛的应用，它从未标记图像中学习高质量的可传递表示.为了达到同样的目的，本文提出了一种基于语言辅助表示的掩蔽图像预训练方法MILAN，该方法不需要预测原始像素或低层特征，我们的预训练目标是利用字幕监控所获得的大量语义信号来重建图像特征，我们提出了一种更有效的提示解码器体系结构和语义感知掩码采样机制，进一步提高了预训练模型的传递性能，实验结果表明MILAN算法具有更高的准确率。在ImageNet-1K数据集上，采用224x224的输入分辨率，对屏蔽后的自动编码器进行预训练和微调，MILAN在ViTB 16数据集上取得了85.4%的前1位准确率，比之前的最高水平高出1个百分点。在下游语义分割任务中，MILAN在ADE20K数据集上使用ViT-B 16骨干网取得了52.7 mIoU的准确率。优于先前的掩蔽预训练结果4个点。    
利用字幕监控所获得的大量语义信号来重建图像特征

-----
What is it like to program with artificial intelligence?   
大型语言模型，如OpenAI的codex和Deepmind的AlphaCode，可以生成代码来解决用自然语言表达的各种问题。这项技术已经在至少一个广泛使用的编程编辑器扩展中实现了商业化：GitHub副驾驶。 在本文中，我们将探讨如何使用大型语言模型进行编程（LLM辅助编程）与程序员辅助的先前概念化类似，但又不同。我们利用公开可用的LLM辅助编程经验报告，以及先前的可用性和设计研究。我们发现，虽然LLM辅助编程共享编译、配对编程和通过搜索和重用编程的一些属性，在技术可能性和实际经验方面都有根本的差别，因此，应当把法学硕士协助的方案编制看作是一种新的方案编制方式，有其独特的性质和挑战。 最后，我们从一个用户研究中得出了一些观察结果，在这个研究中，非专业的最终用户程序员使用LLM辅助工具来解决电子表格中的数据任务。我们讨论了在将大型语言模型应用于最终用户编程时可能出现的问题，以及开放的研究挑战，特别是对于那些很少或没有编程专业知识的用户。    
分析了AI的一个应用场景：编程

----
Incorporating Customer Reviews in Size and Fit Recommendation systems for Fashion E-Commerce    
随着电子商务领域的迅速发展，产品推荐已经成为电子商务公司越来越感兴趣的领域。在产品推荐中比较困难的任务之一是尺寸和合身性预测。在电子时尚领域中存在大量与尺寸相关的退货和退款，这给消费者带来不便，也给公司带来了成本。因此，有一个好的尺寸和合身性推荐系统，该领域的早期工作使用传统的机器学习方法来从购买历史估计客户和产品尺寸，这些方法由于客户—产品数据的巨大稀疏性而遭受冷启动问题，最近，人们已经通过嵌入客户和产品特征来使用深度学习来解决这一问题。但是没有一种方法将产品页面上的有价值的客户反馈与客户和产品特征结合在一起。我们提出一种新的方法，可以使用来自客户评论的信息以及客户和产品特征来进行尺寸和合身性预测。我们在4个数据集上证明了我们的方法与仅使用产品和客户特征相比的有效性。我们的方法在4个不同的数据集上显示了F1（宏观）评分比基线提高了1.37%-4.31%。   
解决了一个实用性问题，是一个论文思路

----
