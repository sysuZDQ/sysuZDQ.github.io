Visual Prompting via Image Inpainting    
如何使预先训练好的视觉模型适应新的下游任务，而不需要特定任务的微调或任何模型修改？受自然语言处理中的提示启发，本文对视觉提示进行了研究：给定在测试时间的新任务的输入—输出图像示例和新的输入图像，目标是自动产生与给定示例一致的输出图像。我们证明，只要修复算法在正确的数据上进行了训练，将这个问题作为简单的图像修复——字面上只是填补串联的视觉提示图像中的一个洞——结果是令人惊讶的有效。我们在一个新的数据集上训练屏蔽的自动编码器，这个数据集来自Arxiv上的学术论文源的88k个未标记的数字。我们将视觉提示应用于这些预先训练的模型，并演示了各种下游图像到图像任务的结果，包括前景分割、单个对象检测、彩色化、边缘检测等。   
我们常见的是NLP上的提示学习，是否视觉上的被忽略了？

----
