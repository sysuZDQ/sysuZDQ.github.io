SSformer: A Lightweight Transformer for Semantic Segmentation    
Transformer在语义分割方面的性能优于卷积神经网络.然而，传统的VisionTransformer算法缺乏局部邻域的归纳偏差，且具有较高的时间复杂度. SwinTransformer算法采用分层结构和移动窗口，在各种视觉任务中创造了新的记录，同时具有更高的效率.然而，由于Swin Transformer是专门为图像分类而设计的，因此在基于密集预测的分割任务中，它的性能可能达不到最优，而且简单地将Swin Transformer与现有的方法相结合会导致最终分割模型的模型大小和参数的增加.本文提出了一种基于Swin Transformer的图像分割方法，我们对Swin Transformer进行了重新思考，设计了一个轻量级但有效的Transformer模型SSformer，在该模型中，我们考虑到Swin Transformer固有的层次化设计，提出了一个解码Transformer来聚合不同层次的信息，实验结果表明，所提出的SSformer具有与现有模型相当的mIoU性能，同时保持较小的模型尺寸和较低的计算。     
对swim transformer的改进

------   
Combined CNN Transformer Encoder for Enhanced Fine-grained Human Action Recognition     
细粒度动作识别是计算机视觉领域的一个挑战性课题.由于细粒度数据集在时间和空间上的类间差异较小，细粒度动作识别模型需要良好的时间推理和属性动作语义的区分.利用CNN捕捉高层次时空特征表示的能力和Transformer捕捉潜在语义和全局依赖的建模效率，我们研究了两种结合CNN视觉中枢和Transformer Encoder来增强细粒度动作识别的框架：1）基于视觉的编码器，用于学习潜在的时间语义; 2）多模态视频—文本交叉编码器，用于利用额外的文本输入，学习视觉语义和文本语义之间的交叉关联.我们的实验结果表明，我们的Transformer框架都能有效地学习潜在的时间语义和跨模态关联，在FineGym基准测试数据集上，我们实现了两种架构的新的最先进的性能。    
CNN和Transformer的结合  

----- 
Re-Attention Transformer for Weakly Supervised Object Localization    
弱监督目标定位是一项具有挑战性的任务，其目标定位的目标具有粗糙的标注，如图像类别.现有的深度网络方法主要基于类激活图，侧重于突出有区别的局部区域，而忽略了整个目标.此外，新兴的基于Transformer的技术不断地将大量的重点放在背景上，这阻碍了识别完整对象的能力。为了解决这些问题，本文提出了一种标记精化Transformer（token refinement transformer TRT（token priority scoring module），它捕捉对象级语义，很好地指导本地化，并引入了一个新的模块——令牌优先级评分模块（TPSM）以抑制背景噪声的影响同时聚焦于目标物体。在两个基准测试上的大量实验表明，与已有的基于图像类别标注的方法相比，本文提出的方法具有更好的性能.源代码可在 url{https: github.com su-hui-zz ReAttentionTransformer}.     
捕捉对象级语义    

----
KPI-BERT: A Joint Named Entity Recognition and Relation Extraction Model for Financial Reports      
我们提出的KPI-BERT，一个系统，采用新的方法命名实体识别（NER）与关系抽取（RE）提取和链接关键绩效指标（KPI），例如“收入”或“利息支出”。具体而言，我们介绍了一种基于Transformers双向编码器表示的端到端可训练体系结构（BERT）组合递归神经网络该模型引入了一种基于RNN的可学习池机制，并通过显式过滤不可能的关系来融合领域专家知识，在德国财务报告的一个新的实际数据集上取得了显著的提高，优于几个强基准，包括竞争的最先进的基于跨度的实体标记方法。    
有一个BERT的扩展    

-------   
 A Study of Modeling Rising Intonation in Cantonese Neural Speech Synthesis   
 在人类语言中，说话者的态度不能单靠文字内容来表达，而必须配合语调。陈述性问句是日常粤语会话中常用的问句，而且通常是用升调来表达的。（TTS）系统由于语义信息的丢失而不能合成这些句子的升调。虽然用额外的语言模型来补充系统已经变得越来越普遍，但是它们在模拟上升语调方面的性能却没有得到很好的研究，我们提出了一个基于BERT的语句 疑问句分类器来补充粤语TTS模型，设计了不同的训练策略并比较了它们的性能。在粤语语料CanTTS上的实验结果表明，分离训练方法具有最好的泛化性能和可行性。   
 对粤语的研究  

 ------  
 Two-Stream Transformer Architecture for Long Video Understanding   
 纯Vision Transformer结构对于短视频分类和动作识别任务是非常有效的，但是由于自注意的二次复杂性和缺乏归纳偏差，长格式视频理解任务放大了变换器中的数据和存储器效率问题，使得当前的方法在数据或存储器受限的域上实现是不可行的。该文提出了一种高效的时空注意网络（Spatio-Temporal Attention Network，STAN），该网络采用双流Transformer结构来建模静态图像特征和时间上下文特征之间的依赖关系，能够在单个GPU上对最长为2分钟的视频进行分类，具有数据高效性，并且在多个长视频理解任务上实现了SOTA性能。     
 双流transformer

 ---- 
 