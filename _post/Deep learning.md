# ***Deep Learning***     
2015年，深度学习三巨头携手撰写了一篇综述性文章[Deep learning](https://www.nature.com/articles/nature14539.pdf)。对于刚入门深度学习的同学来说，这篇文章可能是一个好的选择。   

-----
## ***Learning Deep Neural Network from Scratch***
什么是神经网络呢？或许你的脑海中马上就浮现出一个大致的轮廓，但要你仔细地按照原理娓娓道来你很可能就会磕磕绊绊了。所以，我们要必要清晰把握神经网络的基本思想和发展脉络，以便我们日后能够将自己天马行空的想法付诸于其中！    
### ***A Simple Neural Network***
一个简单的神经网络就是输入为$X=(x_1,x_2,...,x_n)$，得到输出$y$。通过调整权重$W=(w_1,w_2,...,w_n)$使得你输入的$X$能得到你想要的$y$，就比如我们常见的图片分类，输入的$X$是图片的表征，这里的$y$就是我们的类别标记$0,1,2,3.....$，最后将这些数字映射到例如猫，狗，马等标签     
<div align=center><img src="..\image\DL\23b6869fada0eb4acacbf16ef141922.jpg" width="500"></div>  
这时你会想，这个激活函数是干嘛的呀？很显然，仅以一条直线（我们这里以输入为一维来举例，多维的同理）划分区域是远远不够的。因此我们需要引入非线性，这里就是激活函数的意义啦！常见的激活函数如下，但是一般ReLU会用的比较多。 
 <div align=center><img src="..\image\DL\9f8dd136e38433c68c86d7ee6c9cfd7.jpg" width="500"></div>    
 最后，经过多次线性和非线性的变化，就可以达到期望的分类
 <div align=center><img src="..\image\DL\c6466eecad906013013ad4f2219ad61.jpg" width="500"></div>

 好了，我们已经清楚了每个模块的意义。接下来你肯定会好奇训练学习是什么？我们期望得到一个函数，他能使得我们的输入都能得到期望的输出，那么得到这个函数的过程就是训练了！这在里，我们就是要得到权值$W$。因此，我们先随机初始化$W$，然后通过前向传播计算出$y$，此时我们得到的$y$和我们的期望肯定不一样的，那么就我们就需要利用这个差值信息来调整$W$，也就是说我们期望这个差值最小，因此我们寻找的是最小值。这里的做法就是通过[梯度下降](https://www.bilibili.com/video/BV18P4y1j7uH/?spm_id_from=333.788&vd_source=16860f65fea90013288ea5a6ba1bba3a)反向传播回去，使得$W$能不断地朝着目前调整。梯度为0的点就是最低点，因此我们就有了一个目标，朝着梯度下降的地方调整！     
 细心的同学肯定会疑惑，这个最低点可能是极小点而不是全局最小点啊？没错，这确实是一个问题，具体可以看看[这里](https://blog.csdn.net/weixin_42887138/article/details/112499704)的分析
