# 西瓜书复习

## 一 、绪论

机器学习就是基于经验做出的预判

## 二、模型评估与选择

过拟合的解决方法

- 增加数据量（多加点数据、数据增强）
- 正则化（L1、L2 Regularization, Dropout）
- 简化模型（网络结构、训练时间、限制权值、增加噪声）
- 模型融合（Bagging、Boosting、Dropout）
- 贝叶斯方法

欠拟合的解决方法

- 数据未做归一化处理
- 没有使用任何正则化方法
- 使用了一个太大的batch size
- 使用了一个错误的学习率
- 在最后一层使用错误的激活函数
- 使用了一个太深的神经网络
- 隐藏层神经元的数量设置不正确

训练测试集划分方法

- 留出法
- K折交叉验证
- 自助法

模型的评价指标

[(4 封私信 / 80 条消息) 所有的机器学习模型的评价指标都有哪些？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/315563876)

## 线性模型

LDA

## 决策树

划分选择

- 信息增益
- 增益率
- 基尼指数

## 神经网络

模拟生物神经系统对真实世界物体所作出的交互反应

BP算法（基于梯度下降策略）

BP网络过拟合的解决方法

- 早停
- 正则化（在误差目标函数中增加一个用于描述网络复杂度的部分）

跳出局部极小

- 多组初始化
- 模拟退火
- 随机梯度下降
- 遗传算法

级联相关网络（将网络结构也当作学习的目标之一，优点是加速训练，无需确定网络结构，这个思想可以用于论文）

## 支持向量机

它通过在样本空间中找到一个划分超平面，将不同类别的样本分开，同时使得两个点集到此平面的最小距离最大，两个点集中的边缘点到此平面的距离最大

- 硬间隔
- 软间隔
- 非线性

## 贝叶斯分类器

最小化分类错误率

极大似然估计（根据数据采用来估计概率分布参数）

朴素贝叶斯分类器（属性条件独立性假设）

半朴素贝叶斯分类器（考虑一部分属性依赖）

贝叶斯网

EM算法（迭代式方法、坐标下降法、非梯度下降法）

## 集成学习

Boosting（序列化方法）

Bagging和随机森林（并行化方法）

结合策略

- 平均法
- 投票法
- 学习法

多样性（误差-分歧分解，即应好而不同）

多样性增强（引入随机性，即对数据样本、输入属性、输出表示、算法参数进行扰动）

## 聚类

自动形成簇结构、但是对应的语义需要自己定义

性能度量（簇内相似度高、簇间相似度低）

距离计算（闵可夫斯基计算）

原型聚类（极为常用）

- K-means（使得簇内样本尽量紧密）
- 学习向量量化（假设样本具有类别标记）
- 高斯混合聚类（使用概率模型）

密度聚类（假设聚类结构能通过样本分布的紧密程度决定）

层次聚类

## 降维与度量学习

kNN（懒惰学习）

低维嵌入（数据是高维的，但是学习任务是低维的）

主成分分析法

核化线性降维

流形学习

度量学习（对距离度量进行学习）

## 特征选择与稀疏学习

特征选择（减轻维数灾难、降低学习难度，但是要确保不丢失重要特征）

- 过滤式
- 包裹式
- 嵌入式

稀疏表示（矩阵）与字典表示（为稠密的样本找到稀疏的字典）

压缩感知（用部分信息恢复全部信息）

## 计算学习理论

目的是分析学习任务的困难本质，为学习算法提供理论保证，并根据分析结果指导算法设计

## 半监督学习

生成式方法（未标记数据的标记视为缺失参数）

半监督SVM（伪标记的产生基于相似数据具有相同标记的假设）

图半监督学习（把数据集映射为图）

基于分歧的方法

## 概率图模型

隐马尔科夫模型

马尔可夫随机场

条件随机场

## 规则学习

规则是语义明确的

目标是产生一个能覆盖尽可能多样例的规则集

## 强化学习

通常用马尔可夫决策过程来描述